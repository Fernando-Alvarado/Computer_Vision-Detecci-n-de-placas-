{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1bc1539",
   "metadata": {},
   "source": [
    "#  Detección de placas de automóviles en imágenes\n",
    "\n",
    "Este trabajo aborda la detección automática de placas vehiculares en imágenes mediante tres variantes de la familia YOLO (YOLOv11-n, YOLOv11-s y YOLOv10-s), seleccionadas por su bajo costo computacional y reducido número de parámetros.\n",
    "\n",
    "El trabajo se realizo en varios Notebook usando python, por lo que en este se unieron todos los notebooks y se explica el flujo de trabajo.\n",
    "\n",
    "##### Consideraciones\n",
    "\n",
    "+ En caso de ejecutar crear el entorno en conda propuesto en la parte de abajo\n",
    "+  Instalar los siguientes modelos, ver en: (https://docs.ultralytics.com/es/models/)\n",
    "      +  yolov10s.pt\n",
    "      +  yolo11s.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3bddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entorno recmenddo para ejecutar este notebook\n",
    "conda create -n yolov8_env python=3.10 -y\n",
    "conda activate yolov8_env\n",
    "#En caso de tener GPU\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "#En caso de solo tener CPU\n",
    "pip install torch torchvision torchaudio\n",
    "#Otras dependencias\n",
    "pip install ultralytics\n",
    "pip install pandas scikit-learn opencv-python-headless pyyaml matplotlib\n",
    "pip install \"numpy>=1.24,<2.0\"\n",
    "pip install pyarrow --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db38ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from ultralytics import YOLO\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a851337f",
   "metadata": {},
   "source": [
    "### Validacion cruzada\n",
    "\n",
    "El propósito de los siguientes chunks es preparar los datos para validacion cruzada (K-Fold) aplicado en la seleccion de hiperparametros, para ello solo tomamos 10%  de los datos (Dado el coste computacional) en training y test,  posteriormente evaluamos y obtenemos los mejores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade8a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(r\"/Users/pepefv97/Downloads/DATOS_PLACAS/train\")  # raíz original (!Modificar en caso de correr el codigo)\n",
    "IMG_DIR = ROOT / \"images\"\n",
    "LBL_DIR = ROOT / \"labels\"\n",
    "\n",
    "\n",
    "imgs = sorted(IMG_DIR.rglob(\"*.jpg\"))\n",
    "df   = pd.DataFrame({\"img\": imgs})\n",
    "train_df = df.sample(frac=0.10, random_state=123).reset_index(drop=True)\n",
    "\n",
    "\n",
    "K = 5\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b54884",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_ROOT = Path(\"folds\")                     # carpeta raíz donde viven todos los folds\n",
    "OUT_ROOT.mkdir(exist_ok=True)\n",
    "\n",
    "fold_paths = []\n",
    "\n",
    "for fold_i, (tr, va) in enumerate(kf.split(train_df)):\n",
    "    tr_imgs = train_df.iloc[tr][\"img\"].tolist()\n",
    "    va_imgs = train_df.iloc[va][\"img\"].tolist()\n",
    "\n",
    "    # --- 1. Crear la estructura de carpetas -------------------------\n",
    "    fold_dir = OUT_ROOT / f\"fold{fold_i}\"\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        for sub in [\"images\", \"labels\"]:\n",
    "            (fold_dir / split / sub).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # --- 2. Hard‑links para imágenes y labels -----------------------\n",
    "    def link(img_path, dst_img_dir):\n",
    "        src_img = Path(img_path)\n",
    "        src_lbl = LBL_DIR / src_img.with_suffix(\".txt\").name\n",
    "        dst_img = dst_img_dir / src_img.name\n",
    "        dst_lbl = dst_img_dir.parent / \"labels\" / src_lbl.name\n",
    "        os.link(src_img, dst_img)   # crea enlace duro a la imagen\n",
    "        os.link(src_lbl, dst_lbl)   # crea enlace duro al .txt\n",
    "\n",
    "    for p in tr_imgs:\n",
    "        link(p, fold_dir / \"train\" / \"images\")\n",
    "    for p in va_imgs:\n",
    "        link(p, fold_dir / \"val\" / \"images\")\n",
    "\n",
    "    # --- 3. YAML: usa rutas directas de este fold (¡sin duplicar!) --\n",
    "    yaml.dump(\n",
    "        {\n",
    "            \"train\": str((fold_dir / \"train\" / \"images\").resolve()),\n",
    "            \"val\":   str((fold_dir / \"val\"   / \"images\").resolve()),\n",
    "            \"nc\": 1,\n",
    "            \"names\": [\"PLACA_AUTOMOVIL\"]\n",
    "        },\n",
    "        open(fold_dir / \"data.yaml\", \"w\")\n",
    "    )\n",
    "\n",
    "    fold_paths.append(fold_dir / \"data.yaml\")   # guardar ruta para entrenos posteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b126ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"optimizer\": [\"SGD\", \"AdamW\"],             # mejores en detección :contentReference[oaicite:3]{index=3}\n",
    "    \"lr0\": [0.001, 0.005],\n",
    "    \"weight_decay\": [1e-4, 5e-4],\n",
    "    \"mosaic\": [0.5, 1.0]\n",
    "}\n",
    "grid = [dict(zip(param_grid, v)) for v in product(*param_grid.values())]\n",
    "\n",
    "params_train = dict(epochs=3, batch=32, imgsz=640,\n",
    "              device=\"mps\", freeze=10, plots=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f3772",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cfg in grid:\n",
    "    for fold_yaml in fold_paths:\n",
    "        name = (\n",
    "            f\"{Path(fold_yaml).parent.name}\"\n",
    "            f\"_opt-{cfg['optimizer']}\"\n",
    "            f\"_lr{cfg['lr0']}\"\n",
    "            f\"_wd{cfg['weight_decay']}\"\n",
    "            f\"_mos{cfg['mosaic']}\"\n",
    "        )\n",
    "        YOLO(\"yolo11n.pt\").train(\n",
    "            data=str(fold_yaml),\n",
    "            project=\"cross_validation_hpt\",\n",
    "            name=name,\n",
    "            **cfg,\n",
    "            **params_train\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8470f5b2",
   "metadata": {},
   "source": [
    "Observando las metricas de nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b823d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# LEER TODOS LOS metrics.csv Y AGREGAR POR COMBINACIÓN\n",
    "# -------------------------------------------------------------\n",
    "import glob, re, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT_RUNS = Path(\"cross_validation_hpt\")   # carpeta raíz de tus runs\n",
    "pattern   = re.compile(\n",
    "    r\"fold\\d+_\"            # foldX_\n",
    "    r\"opt-(?P<opt>\\w+)_\"\n",
    "    r\"lr(?P<lr>[\\d.]+)_\"\n",
    "    r\"wd(?P<wd>[\\d.]+)_\"\n",
    "    r\"mos(?P<mos>[\\d.]+)\"\n",
    ")  # ← extrae hiperparámetros del nombre de carpeta\n",
    "\n",
    "records = []\n",
    "\n",
    "for csv in ROOT_RUNS.rglob(\"results.csv\"):\n",
    "    run_dir = csv.parent\n",
    "    m = pattern.search(run_dir.name)\n",
    "    if not m:\n",
    "        continue  # ignora carpetas que no sigan el patrón\n",
    "    hp = m.groupdict()                 # dict con opt, lr, wd, mos\n",
    "    df = pd.read_csv(csv)\n",
    "    best_map50 = df[\"metrics/mAP50(B)\"].max()     # mejor época\n",
    "    fold       = run_dir.name.split(\"_\")[0]     # fold0, fold1…\n",
    "    records.append({**hp, \"fold\": fold, \"mAP50\": best_map50})\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# PROMEDIAR Y CALCULAR (media ± std) POR COMBINACIÓN\n",
    "# -------------------------------------------------------------\n",
    "df = pd.DataFrame(records)\n",
    "group_cols = [\"opt\", \"lr\", \"wd\", \"mos\"]\n",
    "summary = (\n",
    "    df.groupby(group_cols)[\"mAP50\"]\n",
    "      .agg([\"mean\", \"std\", \"count\"])\n",
    "      .reset_index()\n",
    "      .sort_values(\"mean\", ascending=False)\n",
    ")\n",
    "print(summary.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248ce24a",
   "metadata": {},
   "source": [
    "Entrenando nuestro modelo con los mejores hiperparametros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f88377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "path_yml = r'/Users/pepefv97/Downloads/DATOS_PLACAS/data.yaml'\n",
    "\n",
    "\n",
    "model = YOLO(\"yolo11n.pt\")      \n",
    "model.train(\n",
    "    data=path_yml,      \n",
    "    epochs=10,                \n",
    "    batch=32,\n",
    "    imgsz=640,\n",
    "    device=\"mps\",\n",
    "    optimizer=\"AdamW\",\n",
    "    lr0=0.001,\n",
    "    weight_decay=0.0001,\n",
    "    mosaic=1.0,                \n",
    "    freeze=10,                  \n",
    "    plots=True,\n",
    "    project=\"ENTRENAMIENTO_YOLOV11\",\n",
    "    name=\"YOLOV11_AdamW_lr0.001_wd1e-4_mos1.0\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184fb649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# LEER TODOS LOS metrics.csv Y AGREGAR POR COMBINACIÓN\n",
    "# -------------------------------------------------------------\n",
    "import glob, re, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT_RUNS = Path(\"yolov11_cross_validation_hpt\")\n",
    "pattern   = re.compile(\n",
    "    r\"fold\\d+_\"                # foldX_\n",
    "    r\"opt-(?P<opt>\\w+)_\"\n",
    "    r\"lr(?P<lr>[\\d.]+)_\"\n",
    "    r\"wd(?P<wd>[\\d.]+)_\"\n",
    "    r\"mos(?P<mos>[\\d.]+)\"\n",
    ")\n",
    "\n",
    "records = []\n",
    "\n",
    "for csv in ROOT_RUNS.rglob(\"results.csv\"):\n",
    "    run_dir = csv.parent\n",
    "    m = pattern.search(run_dir.name)\n",
    "    if not m:\n",
    "        continue                                           # ignora carpetas mal nombradas\n",
    "    hp = m.groupdict()                                     # hiperparámetros\n",
    "    df = pd.read_csv(csv)\n",
    "\n",
    "    # --- localizar la FILA con el mejor mAP50 ---\n",
    "    best_row        = df.loc[df[\"metrics/mAP50(B)\"].idxmax()]\n",
    "    best_map50      = best_row[\"metrics/mAP50(B)\"]\n",
    "    best_map5095    = best_row[\"metrics/mAP50-95(B)\"]      # <- misma época\n",
    "\n",
    "    records.append({\n",
    "        **hp,\n",
    "        \"fold\"     : run_dir.name.split(\"_\")[0],           # fold0, fold1…\n",
    "        \"mAP50\"    : best_map50,\n",
    "        \"mAP50_95\" : best_map5095\n",
    "    })\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# PROMEDIAR (media ± std) POR COMBINACIÓN\n",
    "# -------------------------------------------------------------\n",
    "df = pd.DataFrame(records)\n",
    "group_cols = [\"opt\", \"lr\", \"wd\", \"mos\"]\n",
    "\n",
    "summary = (\n",
    "    df.groupby(group_cols)\n",
    "      .agg(\n",
    "          mean    = (\"mAP50\",    \"mean\"),   # igual que antes\n",
    "          std     = (\"mAP50\",    \"std\"),\n",
    "          count   = (\"fold\",     \"count\"),\n",
    "          mean95  = (\"mAP50_95\", \"mean\"),   # nuevas columnas\n",
    "          std95   = (\"mAP50_95\", \"std\")\n",
    "      )\n",
    "      .reset_index()\n",
    "      .sort_values(\"mean\", ascending=False)  # mismo criterio de orden\n",
    ")\n",
    "\n",
    "print(summary.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225a3a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# LEER TODOS LOS metrics.csv Y AGREGAR POR COMBINACIÓN\n",
    "# -------------------------------------------------------------\n",
    "import glob, re, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT_RUNS = Path(\"yolov10_cross_validation_hpt\")\n",
    "pattern   = re.compile(\n",
    "    r\"fold\\d+_\"                # foldX_\n",
    "    r\"opt-(?P<opt>\\w+)_\"\n",
    "    r\"lr(?P<lr>[\\d.]+)_\"\n",
    "    r\"wd(?P<wd>[\\d.]+)_\"\n",
    "    r\"mos(?P<mos>[\\d.]+)\"\n",
    ")\n",
    "\n",
    "records = []\n",
    "\n",
    "for csv in ROOT_RUNS.rglob(\"results.csv\"):\n",
    "    run_dir = csv.parent\n",
    "    m = pattern.search(run_dir.name)\n",
    "    if not m:\n",
    "        continue                                           # ignora carpetas mal nombradas\n",
    "    hp = m.groupdict()                                     # hiperparámetros\n",
    "    df = pd.read_csv(csv)\n",
    "\n",
    "    # --- localizar la FILA con el mejor mAP50 ---\n",
    "    best_row        = df.loc[df[\"metrics/mAP50(B)\"].idxmax()]\n",
    "    best_map50      = best_row[\"metrics/mAP50(B)\"]\n",
    "    best_map5095    = best_row[\"metrics/mAP50-95(B)\"]      # <- misma época\n",
    "\n",
    "    records.append({\n",
    "        **hp,\n",
    "        \"fold\"     : run_dir.name.split(\"_\")[0],           # fold0, fold1…\n",
    "        \"mAP50\"    : best_map50,\n",
    "        \"mAP50_95\" : best_map5095\n",
    "    })\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# PROMEDIAR (media ± std) POR COMBINACIÓN\n",
    "# -------------------------------------------------------------\n",
    "df = pd.DataFrame(records)\n",
    "group_cols = [\"opt\", \"lr\", \"wd\", \"mos\"]\n",
    "\n",
    "summary = (\n",
    "    df.groupby(group_cols)\n",
    "      .agg(\n",
    "          mean    = (\"mAP50\",    \"mean\"),   # igual que antes\n",
    "          std     = (\"mAP50\",    \"std\"),\n",
    "          count   = (\"fold\",     \"count\"),\n",
    "          mean95  = (\"mAP50_95\", \"mean\"),   # nuevas columnas\n",
    "          std95   = (\"mAP50_95\", \"std\")\n",
    "      )\n",
    "      .reset_index()\n",
    "      .sort_values(\"mean\", ascending=False)  # mismo criterio de orden\n",
    ")\n",
    "\n",
    "print(summary.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e8520",
   "metadata": {},
   "source": [
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2796ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"optimizer\":     [\"SGD\", \"AdamW\"],\n",
    "    \"lr0\":           [1e-3, 5e-4], # Tasa de aprendizaje de nuestro modelo\n",
    "    \"weight_decay\":  [1e-4, 5e-4], # Tasa de decaimiento, para evitar el sobreajuste\n",
    "    \"mosaic\":        [0,0.5]\n",
    "}\n",
    "\n",
    "grid = [dict(zip(param_grid, v)) for v in product(*param_grid.values())]\n",
    "\n",
    "params_train = dict(\n",
    "    epochs=3, # Numero de epocas a entrenar el modelo\n",
    "    batch=32, # Tamaño del batch (Cuantas imagenes se entrenan al mismo tiempo)\n",
    "    imgsz=512, # Tamaño de las imagenes a entrenar\n",
    "    device=\"mps\", # Dispositvo a usar, (\"mps\" para Mac con chip M1/M2, \"cuda\" para GPU Nvidia, \"cpu\" para CPU) (!En cado de correr el modelo cambiar la configuración del dispositivo!)\n",
    "    freeze=10, # Congelar las primeras 10 capas del modelo (Se aplica en transfer learning)\n",
    "    plots=True, # Mostrar las graficas de entrenamiento\n",
    "    verbose=True, # Muestra info mas detallada del entrenamiento\n",
    "    amp=True # Usar precision mixta (Mejora el rendimiento en GPU)\n",
    ")\n",
    "\n",
    "fold_paths = ['folds/fold0/data.yaml','folds/fold1/data.yaml','folds/fold2/data.yaml','folds/fold3/data.yaml','folds/fold4/data.yaml'] #Nombres de las carpetas de los folds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e3e586",
   "metadata": {},
   "source": [
    "### Ejecutando con nuestro modelo yolov10s.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4869a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generando un folder con  nombre para cada cada experimento especificando los hiperparametros\n",
    "for cfg in grid:\n",
    "    for fold_yaml in fold_paths:\n",
    "        name = (\n",
    "            f\"{Path(fold_yaml).parent.name}\"\n",
    "            f\"_opt-{cfg['optimizer']}\"\n",
    "            f\"_lr{cfg['lr0']}\"\n",
    "            f\"_wd{cfg['weight_decay']}\"\n",
    "            f\"_mos{cfg['mosaic']}\"\n",
    "        )\n",
    "        YOLO(\"yolov10s.pt\").train( # Entremaneiento con el modelo YOLOv10s\n",
    "            data=str(fold_yaml),\n",
    "            project=\"yolov10_cross_validation_hpt\",\n",
    "            name=name,\n",
    "            **cfg,\n",
    "            **params_train\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c007d66",
   "metadata": {},
   "source": [
    "Codigo para ir leyendo los resultados que nos dio nuestros modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee974431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# LEER TODOS LOS metrics.csv Y AGREGAR POR COMBINACIÓN\n",
    "# -------------------------------------------------------------\n",
    "import glob, re, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT_RUNS = Path(\"yolov10_cross_validation_hpt\")   # carpeta raíz de tus runs\n",
    "pattern   = re.compile(\n",
    "    r\"fold\\d+_\"            # foldX_\n",
    "    r\"opt-(?P<opt>\\w+)_\"\n",
    "    r\"lr(?P<lr>[\\d.]+)_\"\n",
    "    r\"wd(?P<wd>[\\d.]+)_\"\n",
    "    r\"mos(?P<mos>[\\d.]+)\"\n",
    ")  # ← extrae hiperparámetros del nombre de carpeta\n",
    "\n",
    "records = []\n",
    "\n",
    "for csv in ROOT_RUNS.rglob(\"results.csv\"):\n",
    "    run_dir = csv.parent\n",
    "    m = pattern.search(run_dir.name)\n",
    "    if not m:\n",
    "        continue  # ignora carpetas que no sigan el patrón\n",
    "    hp = m.groupdict()                 # dict con opt, lr, wd, mos\n",
    "    df = pd.read_csv(csv)\n",
    "    best_map50 = df[\"metrics/mAP50(B)\"].max()     # mejor época\n",
    "    fold       = run_dir.name.split(\"_\")[0]     # fold0, fold1…\n",
    "    records.append({**hp, \"fold\": fold, \"mAP50\": best_map50})\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# PROMEDIAR Y CALCULAR (media ± std) POR COMBINACIÓN\n",
    "# -------------------------------------------------------------\n",
    "df = pd.DataFrame(records)\n",
    "group_cols = [\"opt\", \"lr\", \"wd\", \"mos\"]\n",
    "summary = (\n",
    "    df.groupby(group_cols)[\"mAP50\"]\n",
    "      .agg([\"mean\", \"std\", \"count\"])\n",
    "      .reset_index()\n",
    "      .sort_values(\"mean\", ascending=False)\n",
    ")\n",
    "print(summary.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df45a7a4",
   "metadata": {},
   "source": [
    "Ejecutando el modelo con los mejores hiperparametros encontrados en el chunk anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3486c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "path_yml = r'/Users/pepefv97/Downloads/DATOS_PLACAS/data.yaml'\n",
    "\n",
    "\n",
    "model = YOLO(\"yolov10s.pt\")      \n",
    "model.train(\n",
    "    data=path_yml, \n",
    "    epochs=10,\n",
    "    batch=32,\n",
    "    imgsz=512,\n",
    "    device=\"mps\",\n",
    "    freeze=10,\n",
    "    plots=True,\n",
    "    verbose=True,\n",
    "    amp=True,\n",
    "    optimizer=\"AdamW\",\n",
    "    lr0=0.0005,\n",
    "    weight_decay=0.0005,\n",
    "    mosaic=0,                \n",
    "    project=\"ENTRENAMIENTO_YOLOV10S\",\n",
    "    name=\"YOLOV10S_AdamW_lr0.0005_wd0.0005_mos0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b129de19",
   "metadata": {},
   "source": [
    "### Ejecutando con nuestro modelo yolo11s.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4838e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cfg in grid:\n",
    "    for fold_yaml in fold_paths:\n",
    "        name = (\n",
    "            f\"{Path(fold_yaml).parent.name}\"\n",
    "            f\"_opt-{cfg['optimizer']}\"\n",
    "            f\"_lr{cfg['lr0']}\"\n",
    "            f\"_wd{cfg['weight_decay']}\"\n",
    "            f\"_mos{cfg['mosaic']}\"\n",
    "        )\n",
    "        YOLO(\"yolo11s.pt\").train(\n",
    "            data=str(fold_yaml),\n",
    "            project=\"yolov11_cross_validation_hpt\",\n",
    "            name=name,\n",
    "            **cfg,\n",
    "            **params_train\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d346d7f",
   "metadata": {},
   "source": [
    "Codigo para ir leyendo los resultados que nos dio nuestros modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb51a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# LEER TODOS LOS metrics.csv Y AGREGAR POR COMBINACIÓN\n",
    "# -------------------------------------------------------------\n",
    "import glob, re, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT_RUNS = Path(\"yolov11_cross_validation_hpt\")   # carpeta raíz de tus runs\n",
    "pattern   = re.compile(\n",
    "    r\"fold\\d+_\"            # foldX_\n",
    "    r\"opt-(?P<opt>\\w+)_\"\n",
    "    r\"lr(?P<lr>[\\d.]+)_\"\n",
    "    r\"wd(?P<wd>[\\d.]+)_\"\n",
    "    r\"mos(?P<mos>[\\d.]+)\"\n",
    ")  # ← extrae hiperparámetros del nombre de carpeta\n",
    "\n",
    "records = []\n",
    "\n",
    "for csv in ROOT_RUNS.rglob(\"results.csv\"):\n",
    "    run_dir = csv.parent\n",
    "    m = pattern.search(run_dir.name)\n",
    "    if not m:\n",
    "        continue  # ignora carpetas que no sigan el patrón\n",
    "    hp = m.groupdict()                 # dict con opt, lr, wd, mos\n",
    "    df = pd.read_csv(csv)\n",
    "    best_map50 = df[\"metrics/mAP50(B)\"].max()     # mejor época\n",
    "    fold       = run_dir.name.split(\"_\")[0]     # fold0, fold1…\n",
    "    records.append({**hp, \"fold\": fold, \"mAP50\": best_map50})\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# PROMEDIAR Y CALCULAR (media ± std) POR COMBINACIÓN\n",
    "# -------------------------------------------------------------\n",
    "df = pd.DataFrame(records)\n",
    "group_cols = [\"opt\", \"lr\", \"wd\", \"mos\"]\n",
    "summary = (\n",
    "    df.groupby(group_cols)[\"mAP50\"]\n",
    "      .agg([\"mean\", \"std\", \"count\"])\n",
    "      .reset_index()\n",
    "      .sort_values(\"mean\", ascending=False)\n",
    ")\n",
    "print(summary.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ce34d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea38397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecuentando el modelo con los mejores hiperparametros encontrados\n",
    "\n",
    "path_yml = r'/Users/pepefv97/Downloads/DATOS_PLACAS/data.yaml'\n",
    "\n",
    "\n",
    "model = YOLO(\"yolo11s.pt\")      \n",
    "model.train(\n",
    "    data=path_yml, \n",
    "    epochs=10,\n",
    "    batch=32,\n",
    "    imgsz=512,\n",
    "    device=\"mps\",\n",
    "    freeze=10,\n",
    "    plots=True,\n",
    "    verbose=True,\n",
    "    amp=True,\n",
    "    optimizer=\"AdamW\",\n",
    "    lr0=0.0005,\n",
    "    weight_decay=0.0005,\n",
    "    mosaic=0,                \n",
    "    project=\"ENTRENAMIENTO_YOLOV11S\",\n",
    "    name=\"YOLOV11S_AdamW_lr0.0005_wd0.0005_mos0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a857084f",
   "metadata": {},
   "source": [
    "### Evaluacion del modelo usando Boostrap\n",
    "\n",
    "En este notebook se va a realizar el código para la evaluacion de los tres modelos entrenados. Para esto se sacarán las métricas $mAP50$ y $mAP50-95$ directamente sobre el conjunto de entrenamiento, así como generar intervalos de confianza para estas utilizando el método de Bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd6a8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v11n = YOLO('ENTRENAMIENTO_YOLOV11/YOLOV11_AdamW_lr0.001_wd1e-4_mos1.0/weights/best.pt')\n",
    "model_v11s = YOLO('ENTRENAMIENTO_YOLOV11S/YOLOV11S_AdamW_lr0.0005_wd0.0005_mos0/weights/best.pt')\n",
    "model_v10s = YOLO('ENTRENAMIENTO_YOLOV10S/YOLOV10S_AdamW_lr0.0005_wd0.0005_mos0/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac908db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros para los modelos\n",
    "metrics_yolov11n = model_v11n.val(\n",
    "    data=r'/Users/pepefv97/Downloads/DATOS_PLACAS/data.yaml',\n",
    "    split='test',\n",
    "    workers=0,      \n",
    "    verbose=False,\n",
    "    save=False,\n",
    "    plots=False,\n",
    "    project=\"EVALUACION\",\n",
    "    name=\"YOLOV11N\",\n",
    "    device=\"mps\",\n",
    "    batch=64\n",
    ")\n",
    "\n",
    "metrics_yolov11s = model_v11s.val(\n",
    "    data=r'/Users/pepefv97/Downloads/DATOS_PLACAS/data.yaml',\n",
    "    split='test',\n",
    "    workers=0,      \n",
    "    verbose=False,\n",
    "    save=False,\n",
    "    plots=False,\n",
    "    project=\"EVALUACION\",\n",
    "    name=\"YOLOV11S\",\n",
    "    device=\"mps\",\n",
    "    batch=64\n",
    ")\n",
    "\n",
    "metrics_yolov10s = model_v10s.val(\n",
    "    data=r'/Users/pepefv97/Downloads/DATOS_PLACAS/data.yaml',\n",
    "    split='test',\n",
    "    workers=0,      \n",
    "    verbose=False,\n",
    "    save=False,\n",
    "    plots=False,\n",
    "    project=\"EVALUACION\",\n",
    "    name=\"YOLOV10S\",\n",
    "    device=\"mps\",\n",
    "    batch=64\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b93459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metricas para los modelos\n",
    "metricas = {\n",
    "    'Precision': metrics_yolov11n.box.mp,\n",
    "    'Recall': metrics_yolov11n.box.mr,\n",
    "    'mAP@0.5': metrics_yolov11n.box.map50,\n",
    "    'mAP@0.5:0.95': metrics_yolov11n.box.map,\n",
    "    'Tiempo Preprocesamiento (ms/img)': metrics_yolov11n.speed['preprocess'],\n",
    "    'Tiempo Inferencia (ms/img)': metrics_yolov11n.speed['inference'],\n",
    "    'Tiempo Postprocesamiento (ms/img)': metrics_yolov11n.speed['postprocess'],\n",
    "    'Número de clases detectadas': metrics_yolov11n.box.nc\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame([metricas])\n",
    "df_metrics.to_csv(\"EVALUACION/YOLOV11N/metrics_test.csv\", index=False)\n",
    "\n",
    "\n",
    "metricas_10s = {\n",
    "    'Precision': metrics_yolov10s.box.mp,\n",
    "    'Recall': metrics_yolov10s.box.mr,\n",
    "    'mAP@0.5': metrics_yolov10s.box.map50,\n",
    "    'mAP@0.5:0.95': metrics_yolov10s.box.map,\n",
    "    'Tiempo Preprocesamiento (ms/img)': metrics_yolov10s.speed['preprocess'],\n",
    "    'Tiempo Inferencia (ms/img)': metrics_yolov10s.speed['inference'],\n",
    "    'Tiempo Postprocesamiento (ms/img)': metrics_yolov10s.speed['postprocess'],\n",
    "    'Número de clases detectadas': metrics_yolov10s.box.nc\n",
    "}\n",
    "\n",
    "df_metrics_10s = pd.DataFrame([metricas_10s])\n",
    "df_metrics_10s.to_csv(\"EVALUACION/YOLOV10S/metrics_test.csv\", index=False)\n",
    "\n",
    "\n",
    "metricas_11s = {\n",
    "    'Precision': metrics_yolov11s.box.mp,\n",
    "    'Recall': metrics_yolov11s.box.mr,\n",
    "    'mAP@0.5': metrics_yolov11s.box.map50,\n",
    "    'mAP@0.5:0.95': metrics_yolov11s.box.map,\n",
    "    'Tiempo Preprocesamiento (ms/img)': metrics_yolov11s.speed['preprocess'],\n",
    "    'Tiempo Inferencia (ms/img)': metrics_yolov11s.speed['inference'],\n",
    "    'Tiempo Postprocesamiento (ms/img)': metrics_yolov11s.speed['postprocess'],\n",
    "    'Número de clases detectadas': metrics_yolov11s.box.nc\n",
    "}\n",
    "\n",
    "df_metrics_11s = pd.DataFrame([metricas_11s])\n",
    "df_metrics_11s.to_csv(\"EVALUACION/YOLOV11S/metrics_test.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980cedc0",
   "metadata": {},
   "source": [
    "**Generación de intervalos de confianza para las métricas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, pathlib, os, shutil, yaml, uuid\n",
    "\n",
    "B  = 1000                              \n",
    "TEST_IMG = pathlib.Path(\"/Users/pepefv97/Downloads/DATOS_PLACAS/test/images\")   \n",
    "TEST_LAB = pathlib.Path(\"/Users/pepefv97/Downloads/DATOS_PLACAS/test/labels\")   \n",
    "BOOT_ROOT = pathlib.Path(\"BOOTSTRAP/SETS\")\n",
    "CLASS_NAME = [\"PLACA_AUTOMOVIL\"] \n",
    "ROOT_PATH = pathlib.Path(\"/Users/pepefv97/Downloads/PROYECTO_5\")\n",
    "imgs = sorted(TEST_IMG.glob(\"*.jpg\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)                               \n",
    "\n",
    "for b in range(B):\n",
    "    set_dir  = ROOT_PATH / BOOT_ROOT / f\"set_{b:04d}\"\n",
    "    img_dir  = ROOT_PATH / set_dir / \"test/images\"\n",
    "    lab_dir  = ROOT_PATH / set_dir / \"test/labels\"\n",
    "    img_dir.mkdir(parents=True, exist_ok=True)\n",
    "    lab_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    sample = random.choices(imgs, k=len(imgs))  \n",
    "    for idx, src in enumerate(sample):\n",
    "        tag      = f\"{idx:04d}_{uuid.uuid4().hex[:6]}\"\n",
    "        dst_img  = img_dir / f\"{tag}_{src.name}\"\n",
    "        dst_lab  = lab_dir / f\"{tag}_{src.stem}.txt\"\n",
    "\n",
    "        os.symlink(src.resolve(), dst_img)      # enlace a la imagen\n",
    "        os.symlink((TEST_LAB / f\"{src.stem}.txt\").resolve(), dst_lab)\n",
    "\n",
    "    yaml_path = set_dir / \"data.yaml\"\n",
    "    yaml_path.write_text(yaml.dump({\n",
    "        \"names\": CLASS_NAME,\n",
    "        \"nc\"   : len(CLASS_NAME),\n",
    "        \"train\" : str(img_dir),\n",
    "        \"val\" : str(img_dir),\n",
    "        \"test\" : str(img_dir)\n",
    "    }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b381c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, time, pandas as pd\n",
    "from ultralytics import YOLO\n",
    "\n",
    "BOOT_SETS = ROOT_PATH / BOOT_ROOT \n",
    "OUT_ROOT = ROOT_PATH / pathlib.Path(\"BOOTSTRAP\")     \n",
    "DEVICE = \"mps\"                            \n",
    "BATCH = 64                               \n",
    "\n",
    "\n",
    "MODELS = {\n",
    "    \"YOLOV11N\": \"ENTRENAMIENTO_YOLOV11/YOLOV11_AdamW_lr0.001_wd1e-4_mos1.0/weights/best.pt\",\n",
    "    \"YOLOV11S\": \"ENTRENAMIENTO_YOLOV11S/YOLOV11S_AdamW_lr0.0005_wd0.0005_mos0/weights/best.pt\",\n",
    "    \"YOLOV11M\": \"ENTRENAMIENTO_YOLOV10S/YOLOV10S_AdamW_lr0.0005_wd0.0005_mos0/weights/best.pt\"\n",
    "}\n",
    "\n",
    "yaml_files = sorted(BOOT_SETS.glob(\"set_*/data.yaml\"))\n",
    "assert yaml_files, \"No se encontraron réplicas en BOOTSTRAP/SETS/\"\n",
    "\n",
    "rows = []\n",
    "for model_name, model_path in MODELS.items():\n",
    "    print(f\"Evaluando {model_name} …\")\n",
    "    model = YOLO(model_path)               \n",
    "\n",
    "    for yml in yaml_files:\n",
    "        start = time.time()\n",
    "        r = model.val(\n",
    "            data=str(yml),\n",
    "            split=\"test\",\n",
    "            batch=BATCH,\n",
    "            device=DEVICE,\n",
    "            workers=0,      \n",
    "            verbose=False,\n",
    "            save=False,\n",
    "            plots=False\n",
    "        )\n",
    "\n",
    "        rows.append({\n",
    "            \"Model\"   : model_name,\n",
    "            \"Sample\"  : yml.parent.name,     \n",
    "            \"Precision\": r.box.mp,\n",
    "            \"Recall\"   : r.box.mr,\n",
    "            \"mAP50\"    : r.box.map50,\n",
    "            \"mAP5095\"  : r.box.map,\n",
    "            \"Pre_ms\"   : r.speed[\"preprocess\"],\n",
    "            \"Inf_ms\"   : r.speed[\"inference\"],\n",
    "            \"Post_ms\"  : r.speed[\"postprocess\"],\n",
    "            \"Elapsed_s\": round(time.time() - start, 2)\n",
    "        })\n",
    "\n",
    "    out_dir = OUT_ROOT / model_name\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "    (pd.DataFrame([r for r in rows if r[\"Model\"] == model_name])\n",
    "        .drop(columns=\"Model\")\n",
    "        .to_csv(out_dir / \"bootstrap_metrics.csv\", index=False))\n",
    "\n",
    "print(\"CSV listos en BOOTSTRAP/<MODEL>/bootstrap_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2920a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "csv_files = {\n",
    "    \"YOLOv11-n\": Path(\"/Users/pepefv97/Downloads/PROYECTO_5/BOOTSTRAP/YOLOV11N/bootstrap_metrics.csv\"),\n",
    "    \"YOLOv11-s\": Path(\"/Users/pepefv97/Downloads/PROYECTO_5/BOOTSTRAP/YOLOV11S/bootstrap_metrics.csv\"),\n",
    "    \"YOLOv10-s\": Path(\"/Users/pepefv97/Downloads/PROYECTO_5/BOOTSTRAP/YOLOV10S/bootstrap_metrics.csv\"),\n",
    "}\n",
    "\n",
    "# Métricas numéricas sobre las que quieres intervalos\n",
    "metric_cols = [\n",
    "    \"Precision\", \"Recall\",\n",
    "    \"mAP50\", \"mAP5095\",\n",
    "    \"Pre_ms\", \"Inf_ms\", \"Post_ms\"\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for model, path in csv_files.items():\n",
    "    df = pd.read_csv(path, usecols=metric_cols)\n",
    "    ci_low  = df.quantile(0.025)\n",
    "    ci_high = df.quantile(0.975)\n",
    "    median  = df.median()\n",
    "\n",
    "    for col in metric_cols:\n",
    "        rows.append({\n",
    "            \"Model\": model,\n",
    "            \"Metric\": col,\n",
    "            \"Median\": median[col],\n",
    "            \"CI_low\": ci_low[col],\n",
    "            \"CI_high\": ci_high[col]\n",
    "        })\n",
    "\n",
    "summary = pd.DataFrame(rows)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2) Guarda el DataFrame (o imprímelo en pantalla)\n",
    "# -------------------------------------------------------------\n",
    "#summary.to_csv(\"BOOTSTRAP/bootstrap_ci.csv\", index=False)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a644232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Rutas a los CSV de réplicas bootstrap (uno por modelo)\n",
    "csv_files = {\n",
    "    \"YOLOv11-n\": Path(\"/Users/pepefv97/Downloads/PROYECTO_5/BOOTSTRAP/YOLOV11N/bootstrap_metrics.csv\"),\n",
    "    \"YOLOv11-s\": Path(\"/Users/pepefv97/Downloads/PROYECTO_5/BOOTSTRAP/YOLOV11S/bootstrap_metrics.csv\"),\n",
    "    \"YOLOv10-s\": Path(\"/Users/pepefv97/Downloads/PROYECTO_5/BOOTSTRAP/YOLOV10S/bootstrap_metrics.csv\"),\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for model, path in csv_files.items():\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # ---------- tiempo total por imagen ----------\n",
    "    df[\"Time_ms\"] = df[\"Pre_ms\"] + df[\"Inf_ms\"] + df[\"Post_ms\"]\n",
    "\n",
    "    # Inference únicamente\n",
    "    inf_q = df[\"Inf_ms\"].quantile([0.025, 0.50, 0.975])\n",
    "    # Total\n",
    "    tot_q = df[\"Time_ms\"].quantile([0.025, 0.50, 0.975])\n",
    "\n",
    "    rows.append({\n",
    "        \"Model\": model,\n",
    "        \"Inf_median\":  inf_q.loc[0.50],\n",
    "        \"Inf_CI_low\":  inf_q.loc[0.025],\n",
    "        \"Inf_CI_high\": inf_q.loc[0.975],\n",
    "        \"Total_median\":  tot_q.loc[0.50],\n",
    "        \"Total_CI_low\":  tot_q.loc[0.025],\n",
    "        \"Total_CI_high\": tot_q.loc[0.975],\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(rows)\n",
    "#summary.to_csv(\"BOOTSTRAP/bootstrap_time_ci_extended.csv\", index=False)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e015d39",
   "metadata": {},
   "source": [
    "### Graficas del entrenamiento para comprar modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfba723",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gráficas de mAP@0.5 y mAP@0.5:0.95 para tres modelos YOLO\n",
    "con estilo “journal‑ready”.\n",
    "\n",
    "Requisitos:\n",
    "  pip install pandas matplotlib scienceplots\n",
    "\"\"\"\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import matplotlib as mpl\n",
    "import scienceplots\n",
    "\n",
    "mpl.rcdefaults()\n",
    "plt.style.use(['science', 'no-latex', 'grid'])  # grid = cuadrícula suave\n",
    "\n",
    "# 2.  Sobrescribe las fuentes para acentos ---------------------------\n",
    "mpl.rcParams.update({\n",
    "    \"text.usetex\": False,              # sin motor TeX\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"DejaVu Sans\"],\n",
    "    \"mathtext.fontset\": \"dejavusans\",  # misma fuente en mathtext\n",
    "    \"mathtext.default\": \"regular\",\n",
    "    \"axes.unicode_minus\": False,       # signo menos unicode\n",
    "    # detalles visuales extra\n",
    "    \"figure.dpi\": 300,\n",
    "    \"font.size\": 10,\n",
    "})\n",
    "\n",
    "\n",
    "# scienceplots ha vuelto a poner mathtext.fontset='cm'.\n",
    "# Vuelve a SOBRE-ESCRIBIR:\n",
    "#mpl.rcParams[\"mathtext.fontset\"] = \"dejavusans\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Diccionario modelo → ruta CSV (ajusta rutas según tu estructura)\n",
    "# ------------------------------------------------------------------\n",
    "csv_paths = {\n",
    "    \"YOLOv11-n\": Path(\"/Users/pepefv97/Downloads/PROYECTO_5/ENTRENAMIENTO_YOLOV11/YOLOV11_AdamW_lr0.001_wd1e-4_mos1.0/results.csv\"),\n",
    "    \"YOLOv11-s\": Path(\"/Users/pepefv97/Downloads/PROYECTO_5/ENTRENAMIENTO_YOLOV11S/YOLOV11S_AdamW_lr0.0005_wd0.0005_mos0/results.csv\"),\n",
    "    \"YOLOv10-s\": Path(\"/Users/pepefv97/Downloads/PROYECTO_5/ENTRENAMIENTO_YOLOV10S/YOLOV10S_AdamW_lr0.0005_wd0.0005_mos0/results.csv\")\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Cargar solo las columnas necesarias y agregar el nombre del modelo\n",
    "# ------------------------------------------------------------------\n",
    "frames = []\n",
    "for label, path in csv_paths.items():\n",
    "    df = pd.read_csv(\n",
    "        path\n",
    "    )\n",
    "    df[\"model\"] = label\n",
    "    frames.append(df)\n",
    "\n",
    "data = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pro_palette = [\"#3C5488\",  \n",
    "               \"#E64B35\",  \n",
    "               \"#00A087\"]  \n",
    "\n",
    "line_styles = [\"-\", \"--\", \":\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06efbddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4.8, 3.4))\n",
    "for i, (label, grp) in enumerate(data.groupby(\"model\")):\n",
    "        ax.plot(\n",
    "            grp[\"epoch\"],\n",
    "            grp[\"metrics/mAP50(B)\"],\n",
    "            label=label,\n",
    "            color=pro_palette[i % len(pro_palette)],\n",
    "            linestyle=line_styles[i % len(line_styles)],\n",
    "            marker='o',\n",
    "            markersize=3\n",
    "        )\n",
    "ax.set_xlabel(\"Época\")\n",
    "ax.set_ylabel(\"mAP@0.5\")\n",
    "ax.set_title(\"Métrica mAP@0.5 vs Época\", pad=6)\n",
    "ax.legend(frameon=False)\n",
    "fig.tight_layout()\n",
    "plt.show() \n",
    "\n",
    "fig.savefig(\"map50_vs_epoca.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b19e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4.8, 3.4))\n",
    "for i, (label, grp) in enumerate(data.groupby(\"model\")):\n",
    "        ax.plot(\n",
    "            grp[\"epoch\"],\n",
    "            grp[\"metrics/mAP50-95(B)\"],\n",
    "            label=label,\n",
    "            color=pro_palette[i % len(pro_palette)],\n",
    "            linestyle=line_styles[i % len(line_styles)],\n",
    "            marker='o',\n",
    "            markersize=3\n",
    "        )\n",
    "ax.set_xlabel(\"Época\")\n",
    "ax.set_ylabel(\"mAP@0.5:0.95\")\n",
    "ax.set_title(\"Métrica mAP@0.5:0.95 vs Época\", pad=6)\n",
    "ax.legend(frameon=False)\n",
    "fig.tight_layout()\n",
    "plt.show() \n",
    "\n",
    "fig.savefig(\"map5095_vs_epoca.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd53deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4.8, 3.4))\n",
    "for i, (label, grp) in enumerate(data.groupby(\"model\")):\n",
    "        ax.plot(\n",
    "            grp[\"epoch\"],\n",
    "            grp[\"time\"]/60,\n",
    "            label=label,\n",
    "            color=pro_palette[i % len(pro_palette)],\n",
    "            linestyle=line_styles[i % len(line_styles)],\n",
    "            marker='o',\n",
    "            markersize=3\n",
    "        )\n",
    "ax.set_xlabel(\"Época\")\n",
    "ax.set_ylabel(\"Tiempo cumulado ([minutos])\")\n",
    "ax.set_title(\"Tiempo acumulado de entrenamiento vs Época\", pad=6)\n",
    "ax.legend(frameon=False)\n",
    "fig.tight_layout()\n",
    "plt.show() \n",
    "\n",
    "fig.savefig(\"tiempo_vs_epoca.png\", dpi=300, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacd986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columna de interés\n",
    "col_map50 = \"metrics/mAP50(B)\"\n",
    "\n",
    "# Índice de la fila con mAP@0.5 máximo dentro de cada modelo\n",
    "idx_best_per_model = data.groupby(\"model\")[col_map50].idxmax()\n",
    "\n",
    "# Extraer esas tres filas y (opcional) ordenarlas por mAP@0.5 descendente\n",
    "best_rows = (\n",
    "    data.loc[idx_best_per_model]          # filas ganadoras\n",
    "        .sort_values(col_map50, ascending=False)\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(best_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a7543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc4f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"epoch\"]==10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72253206",
   "metadata": {},
   "source": [
    "### Parte final\n",
    "\n",
    "Una vez teniendo nuestras arquitectura, pesos vamos a probar que tan bien funciona nuestro modelo  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea65ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.engine.results import Results\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "from typing import List, Union, Tuple, Optional\n",
    "import torch\n",
    "\n",
    "class ObjectDetector:\n",
    "    model: YOLO\n",
    "    detections: Optional[Results]\n",
    "    raw_img: Optional[np.ndarray]\n",
    "    crops: List[np.ndarray]\n",
    "    ocr_results: List[str]\n",
    "    ocr_pipe: Optional[object]\n",
    "\n",
    "    def __init__(self, model_name: str) -> None:\n",
    "        \"\"\"Carga el modelo YOLO y prepara atributos.\"\"\"\n",
    "        self.model = YOLO(model_name)\n",
    "        self.detections = None\n",
    "        self.raw_img = None\n",
    "        self.crops = []\n",
    "        self.ocr_results = []\n",
    "        self.ocr_pipe = None\n",
    "\n",
    "    def predict(self, image: Union[str, np.ndarray]) -> Results:\n",
    "        \"\"\"\n",
    "        Realiza detección y guarda la imagen original en alta resolución en `self.raw_img`.\n",
    "        \"\"\"\n",
    "        # 1) Cargar imagen sin modificar\n",
    "        if isinstance(image, str):\n",
    "            bgr = cv2.imread(image)\n",
    "            if bgr is None:\n",
    "                raise FileNotFoundError(f\"No se pudo leer la imagen: {image}\")\n",
    "            rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            bgr = image.copy()\n",
    "            rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "        self.raw_img = rgb  # guardamos la imagen original :contentReference[oaicite:0]{index=0}\n",
    "\n",
    "        # 2) Inferencia sobre la misma imagen (YOLO letterbox internamente)\n",
    "        self.detections = self.model.predict(rgb, verbose=False)[0]\n",
    "        return self.detections\n",
    "\n",
    "    def extract_crops(self, keep: float = 0.0) -> List[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Extrae recortes de `self.raw_img` usando las cajas en `self.detections`,\n",
    "        preservando la calidad original.\n",
    "        \"\"\"\n",
    "        if self.detections is None or self.raw_img is None:\n",
    "            raise RuntimeError(\"Ejecute primero predict() antes de extract_crops().\")\n",
    "\n",
    "        self.crops.clear()\n",
    "    \n",
    "        for box, conf in zip(\n",
    "            self.detections.boxes.xyxy.cpu().numpy(),\n",
    "            self.detections.boxes.conf.cpu().numpy()\n",
    "        ):\n",
    "            if conf < keep:\n",
    "                continue\n",
    "            x1, y1, x2, y2 = box.astype(int)\n",
    "            crop = self.raw_img[y1:y2, x1:x2]  # recorte directo de original\n",
    "            self.crops.append(crop)\n",
    "\n",
    "        return self.crops\n",
    "\n",
    "    def init_ocr(self, ocr_model_name: str = \"microsoft/trocr-base-printed\") -> None:\n",
    "        \"\"\"Inicializa el pipeline de OCR detectando el mejor dispositivo.\"\"\"\n",
    "        device = \"mps\" if torch.backends.mps.is_available() \\\n",
    "                 else 0 if torch.cuda.is_available() else -1\n",
    "        self.ocr_pipe = pipeline(\"image-to-text\", model=ocr_model_name, device=device)\n",
    "\n",
    "    def ocr_plate(self) -> List[str]:\n",
    "        \"\"\"Aplica OCR sobre cada recorte en `self.crops`.\"\"\"\n",
    "        if not self.crops:\n",
    "            raise RuntimeError(\"Ejecute extract_crops() antes de ocr_plate().\")\n",
    "        if self.ocr_pipe is None:\n",
    "            self.init_ocr()\n",
    "        self.ocr_results = [\n",
    "            self.ocr_pipe(Image.fromarray(c))[0][\"generated_text\"].strip()\n",
    "            for c in self.crops\n",
    "        ]\n",
    "        return self.ocr_results\n",
    "\n",
    "    def show_image(self, mode: str = 'detections',\n",
    "                   figsize: Tuple[float, float] = (8, 6)) -> None:\n",
    "        \"\"\"\n",
    "        Muestra inline (notebook) la imagen con cajas+etiquetas o cada crop,\n",
    "        usando matplotlib para evitar ventanas externas.\n",
    "        \"\"\"\n",
    "        if mode == 'detections':\n",
    "            if self.detections is None or self.raw_img is None:\n",
    "                raise RuntimeError(\"Ejecute predict() antes de show_image().\")\n",
    "            img = self.raw_img.copy()\n",
    "            for box, cls_id, conf in zip(\n",
    "                self.detections.boxes.xyxy.cpu().numpy().astype(int),\n",
    "                self.detections.boxes.cls.cpu().numpy().astype(int),\n",
    "                self.detections.boxes.conf.cpu().numpy()\n",
    "            ):\n",
    "                x1, y1, x2, y2 = box\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "                label = f\"{self.model.names[cls_id]} {conf:.2f}\"\n",
    "                font, fs, th = cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1\n",
    "                (w, h), _ = cv2.getTextSize(label, font, fs, th)\n",
    "                ty = y1 - 5 if y1 - 5 > h else y1 + h + 5\n",
    "                cv2.rectangle(img, (x1, ty-h), (x1+w, ty+2), (0,255,0), cv2.FILLED)\n",
    "                cv2.putText(img, label, (x1, ty), font, fs, (0,0,0), th, cv2.LINE_AA)\n",
    "            plt.figure(figsize=figsize)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        elif mode == 'crops':\n",
    "            if not self.crops:\n",
    "                raise RuntimeError(\"Ejecute extract_crops() antes de show_image().\")\n",
    "            for crop in self.crops:\n",
    "                plt.figure(figsize=figsize)\n",
    "                plt.imshow(crop)\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "        else:\n",
    "            raise ValueError(\"Modo desconocido. Use 'detections' o 'crops'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "det = ObjectDetector('YOLO10S.pt')\n",
    "results = det.predict('PLACA_PATRULLA.jpg')\n",
    "det.show_image(\"detections\")    # muestrar detecciones inline\n",
    "det.extract_crops(keep=0.5)\n",
    "det.show_image(\"crops\")         # muestrar crops inline\n",
    "texts = det.ocr_plate()         # aplicar OCR en MPS/GPU/CPU\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c952adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = det.predict('PLACA_PATRULLA.jpg')\n",
    "det.show_image(\"detections\")    # muestrar detecciones inline\n",
    "det.extract_crops(keep=0.5)\n",
    "det.show_image(\"crops\")         # muestrar crops inline\n",
    "texts = det.ocr_plate() \n",
    "print(\"El texto de la placa es:\")# aplicar OCR en MPS/GPU/CPU\n",
    "print(texts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

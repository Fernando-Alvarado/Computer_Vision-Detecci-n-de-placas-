{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b46a1553-53f7-4b71-b613-8b124bd336e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from ultralytics import YOLO\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2157bbb6-7b49-402f-9e2b-1348a26225c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"optimizer\":     [\"SGD\", \"AdamW\"],\n",
    "    \"lr0\":           [1e-3, 5e-4], # Tasa de aprendizaje de nuestro modelo\n",
    "    \"weight_decay\":  [1e-4, 5e-4], # Tasa de decaimiento, para evitar el sobreajuste\n",
    "    \"mosaic\":        [0,0.5]\n",
    "}\n",
    "\n",
    "grid = [dict(zip(param_grid, v)) for v in product(*param_grid.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "414df604-3e37-4b58-aa8c-a464f2e26d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_train = dict(\n",
    "    epochs=3,\n",
    "    batch=32,\n",
    "    imgsz=512,\n",
    "    device=\"mps\",\n",
    "    freeze=10,\n",
    "    plots=True,\n",
    "    verbose=True,\n",
    "    amp=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7647233-15ba-4169-91f4-4d50e225b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_paths = ['folds/fold0/data.yaml','folds/fold1/data.yaml','folds/fold2/data.yaml','folds/fold3/data.yaml','folds/fold4/data.yaml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a420e8b0-4a63-4581-bc4e-8a1f6568f959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97856a-2690-4da2-b7ff-ab497c1a0675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold0/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold0_opt-SGD_lr0.001_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 158.1±16.2 MB/s, size: 38.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 201.6±47.6 MB/s, size: 37.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.51G      3.492      19.97      3.705         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.706      0.611      0.688      0.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.34G      2.571      2.357      2.706         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.878      0.868      0.923      0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.32G      2.452       1.61      2.515         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.887      0.876      0.933      0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.058 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.886       0.88      0.933      0.596\n",
      "Speed: 0.2ms preprocess, 7.5ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold1/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold1_opt-SGD_lr0.001_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 321.5±134.1 MB/s, size: 39.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 202.7±44.6 MB/s, size: 40.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.56G        3.5      19.77      3.725         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.756      0.561      0.673      0.384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.35G      2.614      2.285      2.703         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.838      0.854      0.889      0.548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.33G      2.492      1.519      2.501         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437       0.89      0.905      0.932      0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.058 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437       0.89      0.905      0.931       0.57\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold2/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold2_opt-SGD_lr0.001_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 369.7±372.1 MB/s, size: 32.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 199.1±65.8 MB/s, size: 39.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.52G      3.529      20.07      3.697         33        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.732       0.67      0.719      0.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3       7.3G      2.621      2.219       2.63         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.879      0.835      0.902      0.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.34G      2.514       1.51      2.495         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.897      0.889       0.93      0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.067 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.897      0.889       0.93      0.572\n",
      "Speed: 0.2ms preprocess, 8.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold3/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold3_opt-SGD_lr0.001_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 223.9±212.1 MB/s, size: 38.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 333.5±343.5 MB/s, size: 39.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.47G      3.516      19.92      3.733         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.751      0.608      0.702      0.411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3       7.4G      2.607      2.229      2.668         32        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.893      0.775      0.884      0.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.35G      2.469      1.534       2.55         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.924      0.824       0.91      0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.067 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.925      0.824       0.91      0.577\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold4/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold4_opt-SGD_lr0.001_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 168.5±109.5 MB/s, size: 36.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 190.9±49.8 MB/s, size: 37.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.52G      3.538      20.01       3.76         32        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.728      0.596      0.671      0.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.41G       2.66       2.29      2.687         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.861      0.771      0.865      0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.39G      2.532      1.615      2.554         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.892      0.807      0.901      0.584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.066 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.893      0.807      0.901      0.584\n",
      "Speed: 0.3ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold0/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold0_opt-SGD_lr0.001_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 131.3±23.7 MB/s, size: 38.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 178.2±48.4 MB/s, size: 37.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.52G      3.485      16.56      3.562         41        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.725      0.708      0.749      0.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.39G      2.721      2.422      2.718         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.921      0.859      0.931      0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      8.37G      2.626      1.728      2.575         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.876      0.919      0.938       0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.094 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.876      0.919      0.938      0.591\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold1/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold1_opt-SGD_lr0.001_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 645.5±521.6 MB/s, size: 39.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 157.8±49.9 MB/s, size: 40.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.51G      3.419         16       3.57         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.506      0.618      0.541       0.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.34G      2.697      2.655      2.819         37        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.818      0.767      0.865      0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.33G        2.6      1.947      2.664         38        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.825      0.847      0.899      0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.085 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.823      0.847      0.899      0.575\n",
      "Speed: 0.2ms preprocess, 6.4ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold2/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold2_opt-SGD_lr0.001_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 182.1±56.7 MB/s, size: 32.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 212.7±44.8 MB/s, size: 39.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.51G      3.485      16.56      3.575         43        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.786      0.661       0.75      0.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.43G      2.724      2.417      2.746         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.871      0.824      0.892       0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.36G      2.585      1.767      2.607         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.906      0.848      0.917      0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.087 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.906      0.847      0.917      0.574\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold3/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold3_opt-SGD_lr0.001_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 209.5±105.3 MB/s, size: 38.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 177.7±54.8 MB/s, size: 39.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.51G      3.513      16.44      3.597         44        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.728      0.659      0.731      0.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.42G      2.716      2.392       2.73         36        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.908       0.82      0.902      0.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.42G      2.562      1.726      2.547         41        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.901      0.855      0.923      0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.087 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449        0.9      0.855      0.923      0.577\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold4/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold4_opt-SGD_lr0.001_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 175.1±108.2 MB/s, size: 36.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 138.8±38.2 MB/s, size: 37.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.53G      3.552      16.58      3.596         43        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.717      0.596       0.68      0.395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3       7.4G      2.713      2.353      2.747         37        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.874       0.81      0.884       0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.39G      2.588      1.776       2.59         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445       0.87      0.854      0.913      0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.083 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.875      0.852      0.913      0.604\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold0/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold0_opt-SGD_lr0.001_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 131.1±20.5 MB/s, size: 38.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 191.3±62.4 MB/s, size: 37.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.55G      3.508      19.79      3.708         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.773      0.671       0.75      0.435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.41G      2.577       2.35      2.703         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.896      0.838       0.92      0.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.34G       2.46      1.584      2.513         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.924      0.861      0.942      0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.923      0.861      0.942      0.594\n",
      "Speed: 0.2ms preprocess, 6.5ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold1/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold1_opt-SGD_lr0.001_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 212.0±116.8 MB/s, size: 39.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 197.9±39.5 MB/s, size: 40.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.52G      3.502      19.77      3.726         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.761      0.558      0.677      0.387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.45G       2.61      2.281      2.702         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437       0.85      0.856      0.912      0.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.37G      2.493      1.519      2.498         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.927      0.876      0.944      0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.927      0.875      0.944      0.585\n",
      "Speed: 0.3ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold2/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold2_opt-SGD_lr0.001_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 206.0±82.0 MB/s, size: 32.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 196.6±63.9 MB/s, size: 39.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.53G      3.529      20.07      3.697         33        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.743      0.621      0.719      0.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.41G       2.62      2.245      2.635         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.853      0.849      0.897      0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.44G      2.522      1.554      2.502         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.885      0.867      0.926      0.579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.887      0.867      0.925      0.579\n",
      "Speed: 0.3ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold3/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold3_opt-SGD_lr0.001_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 317.2±330.7 MB/s, size: 38.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 193.4±39.8 MB/s, size: 39.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.53G      3.516      19.92      3.733         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.745       0.61      0.702      0.411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.42G      2.611      2.224      2.664         32        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.867       0.81       0.88      0.536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.47G      2.476      1.523      2.534         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.894      0.829      0.904      0.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.894      0.831      0.904      0.568\n",
      "Speed: 0.2ms preprocess, 6.6ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold4/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold4_opt-SGD_lr0.001_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 179.1±73.5 MB/s, size: 36.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 192.9±45.4 MB/s, size: 37.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.53G      3.538      20.01      3.761         32        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.704      0.602       0.67        0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.47G      2.664       2.28      2.686         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.827      0.773      0.846       0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.47G      2.517      1.566      2.523         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.852      0.838      0.906      0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.852      0.838      0.906      0.585\n",
      "Speed: 0.2ms preprocess, 6.4ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold0/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold0_opt-SGD_lr0.001_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 154.8±23.4 MB/s, size: 38.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 201.3±38.8 MB/s, size: 37.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.51G      3.486      16.56      3.563         41        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.726      0.676      0.742      0.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.44G      2.724       2.43      2.713         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.911      0.854      0.928      0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.44G      2.626      1.749       2.58         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.904      0.866      0.932      0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.906      0.873      0.932      0.586\n",
      "Speed: 0.2ms preprocess, 6.5ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold0_opt-SGD_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold1/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold1_opt-SGD_lr0.001_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 563.9±460.2 MB/s, size: 39.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 208.7±57.7 MB/s, size: 40.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.53G      3.421         16      3.569         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437       0.52      0.617      0.541      0.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.36G      2.696      2.664      2.815         37        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.758      0.849      0.864      0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.34G        2.6      1.938      2.665         38        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.862      0.842      0.913      0.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.862      0.841      0.914      0.589\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold1_opt-SGD_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold2/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold2_opt-SGD_lr0.001_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 301.1±236.5 MB/s, size: 32.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 211.7±46.2 MB/s, size: 39.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.48G      3.485      16.56      3.575         43        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443       0.79      0.664      0.753      0.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.42G      2.722      2.413      2.741         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.862      0.863      0.901      0.553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3       7.4G      2.581       1.78        2.6         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.922      0.856      0.936      0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.922      0.855      0.936      0.586\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold2_opt-SGD_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold3/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold3_opt-SGD_lr0.001_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 257.8±192.5 MB/s, size: 38.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 195.4±44.2 MB/s, size: 39.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.55G      3.513      16.44      3.598         44        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.715      0.653      0.717       0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.38G      2.724      2.381      2.741         36        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.901      0.817      0.902      0.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.41G      2.562      1.721      2.553         41        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.904       0.86      0.922      0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.908       0.86      0.922      0.575\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold3_opt-SGD_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold4/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold4_opt-SGD_lr0.001_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 197.1±95.6 MB/s, size: 36.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 192.0±48.4 MB/s, size: 37.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.52G      3.552      16.58      3.598         43        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.709      0.609      0.683      0.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.44G      2.709      2.362      2.779         37        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.849      0.813      0.871      0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.38G      2.592      1.774      2.612         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.871      0.869      0.916      0.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.872      0.867      0.916      0.601\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold4_opt-SGD_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold0/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold0_opt-SGD_lr0.0005_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 152.8±11.3 MB/s, size: 38.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 203.6±45.9 MB/s, size: 37.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.52G       3.69      22.14      3.887         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.584      0.402      0.412      0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.48G      2.731      3.214      2.891         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.798      0.832      0.849      0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.46G      2.546      1.987      2.592         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.891       0.87       0.93      0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.048 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.891       0.87       0.93      0.577\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold1/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold1_opt-SGD_lr0.0005_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.1±0.0 ms, read: 261.9±110.9 MB/s, size: 39.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 202.1±49.0 MB/s, size: 40.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.52G      3.668      22.07      3.882         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437       0.33       0.32      0.242      0.126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.46G       2.75      3.328      2.923         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.722      0.721      0.766      0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.39G      2.566      2.036      2.616         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.888      0.831       0.91      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.887      0.833       0.91      0.564\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold2/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold2_opt-SGD_lr0.0005_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 376.1±340.7 MB/s, size: 32.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 206.9±39.9 MB/s, size: 39.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.53G      3.677      22.44      3.903         33        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.446      0.343      0.311      0.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.41G      2.764      3.151      2.878         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.807       0.74      0.822      0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.45G      2.558      1.985      2.605         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.814      0.842      0.884      0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.814      0.841      0.884      0.547\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold3/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold3_opt-SGD_lr0.0005_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 194.8±114.3 MB/s, size: 38.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 197.4±39.3 MB/s, size: 39.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.55G      3.679      22.17      3.923         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.418      0.307      0.299      0.154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.45G      2.771      3.162      2.876         32        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.814      0.742      0.827      0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.44G      2.524      1.959       2.62         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449       0.88      0.785      0.877      0.548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.882      0.784      0.877      0.548\n",
      "Speed: 0.3ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold4/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold4_opt-SGD_lr0.0005_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 229.4±166.1 MB/s, size: 36.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 188.0±44.8 MB/s, size: 37.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.53G        3.7      22.35      3.932         32        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.311      0.362       0.24      0.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.44G      2.804      3.287      2.932         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.771      0.742       0.81      0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.48G      2.587      2.058      2.672         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.891      0.769      0.877      0.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.891      0.769      0.877      0.569\n",
      "Speed: 0.3ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold0/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold0_opt-SGD_lr0.0005_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 181.5±80.5 MB/s, size: 38.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 201.8±47.8 MB/s, size: 37.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.48G      3.621      18.48        3.7         41        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.304      0.322      0.244      0.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.49G      2.819      3.455      2.958         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.686      0.725       0.74      0.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.52G      2.684      2.275      2.713         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.848      0.829      0.901      0.553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.849      0.826      0.901      0.554\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold1/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold1_opt-SGD_lr0.0005_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 298.9±150.4 MB/s, size: 39.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 208.9±61.2 MB/s, size: 40.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.53G      3.574      17.87       3.68         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.305      0.323      0.246      0.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.49G      2.813      3.581       3.05         37        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.643      0.716       0.72      0.435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3       7.5G      2.669      2.441      2.785         38        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.783      0.824      0.868       0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.783      0.824      0.867       0.53\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold2/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold2_opt-SGD_lr0.0005_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 417.0±394.7 MB/s, size: 32.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 217.4±50.4 MB/s, size: 39.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.48G      3.605      18.52      3.695         43        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.373      0.375      0.288      0.145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.47G      2.849      3.306      2.933         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.832      0.804      0.852      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.45G       2.65      2.172      2.692         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.844      0.833      0.895      0.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.845      0.833      0.896      0.556\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold3/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold3_opt-SGD_lr0.0005_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 167.4±59.8 MB/s, size: 38.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 183.8±57.2 MB/s, size: 39.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.56G      3.639      18.34       3.71         44        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.349      0.352      0.269      0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.52G      2.868      3.287      2.943         36        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.807      0.775      0.843      0.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3       7.5G      2.646      2.132      2.679         41        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.923      0.822       0.91      0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.924      0.822       0.91      0.567\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold4/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold4_opt-SGD_lr0.0005_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.1±0.0 ms, read: 183.9±158.1 MB/s, size: 36.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 168.5±53.9 MB/s, size: 37.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.56G      3.682      18.46      3.728         43        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.302      0.337      0.256      0.137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.48G       2.83      3.342      2.987         37        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.799      0.726      0.806       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.48G      2.704       2.21      2.729         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.867      0.809      0.882      0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.867      0.808      0.882      0.574\n",
      "Speed: 0.3ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold0/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold0_opt-SGD_lr0.0005_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 143.1±6.3 MB/s, size: 38.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 200.0±44.2 MB/s, size: 37.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.48G       3.69      22.14      3.887         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.583      0.402      0.412      0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.49G      2.733      3.217      2.893         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.822      0.804      0.853      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.44G      2.546      1.982      2.591         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.879       0.88      0.927      0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.047 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432       0.88      0.879      0.927      0.575\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold1/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold1_opt-SGD_lr0.0005_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 673.2±518.4 MB/s, size: 39.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 205.7±44.5 MB/s, size: 40.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.52G      3.668      22.07      3.882         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437       0.33       0.32      0.242      0.126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.46G      2.747      3.327      2.919         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.684      0.744      0.766      0.457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.41G      2.564      2.037      2.611         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.884      0.854      0.914      0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.048 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.885      0.854      0.914      0.562\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold2/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold2_opt-SGD_lr0.0005_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.1±0.0 ms, read: 151.3±72.2 MB/s, size: 32.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 199.6±44.9 MB/s, size: 39.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.53G      3.676      22.44      3.902         33        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.437      0.343      0.304      0.147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.48G      2.762      3.171      2.878         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.819      0.729      0.826      0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.48G      2.554      1.994      2.608         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.848      0.829      0.887      0.546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.048 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.848      0.832      0.887      0.546\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold3/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold3_opt-SGD_lr0.0005_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 138.0±17.8 MB/s, size: 38.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 189.2±42.5 MB/s, size: 39.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.53G       3.68      22.17      3.923         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.418      0.305      0.299      0.154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.49G      2.771      3.168      2.876         32        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449        0.8      0.771      0.831      0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.46G      2.522      1.963      2.624         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.893      0.782      0.875      0.552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.048 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.891      0.785      0.875      0.551\n",
      "Speed: 0.2ms preprocess, 6.6ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold4/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold4_opt-SGD_lr0.0005_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 191.8±102.2 MB/s, size: 36.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 188.6±47.6 MB/s, size: 37.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.55G        3.7      22.34      3.931         32        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445        0.3      0.364      0.234      0.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.48G      2.802      3.278      2.932         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.779       0.72      0.804      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.47G      2.588      2.059       2.68         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.864       0.78      0.876      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.048 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.862       0.78      0.877      0.564\n",
      "Speed: 0.3ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold0/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold0_opt-SGD_lr0.0005_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 159.3±32.7 MB/s, size: 38.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 218.5±60.3 MB/s, size: 37.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.52G      3.625      18.48      3.701         41        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.301      0.326      0.254       0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.48G      2.816      3.449      2.961         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.684      0.706      0.747      0.457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.48G      2.685      2.276      2.721         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.857      0.782      0.892      0.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.858       0.78      0.891      0.543\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold0_opt-SGD_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold1/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold1_opt-SGD_lr0.0005_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 301.9±178.0 MB/s, size: 39.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 200.7±45.4 MB/s, size: 40.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      8.52G      3.574      17.87       3.68         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.305      0.323      0.246      0.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.43G      2.811      3.579      3.046         37        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.592      0.737      0.669      0.406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.44G      2.669      2.451      2.774         38        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.769      0.794       0.86      0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.769      0.794       0.86      0.534\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold1_opt-SGD_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold2/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold2_opt-SGD_lr0.0005_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 187.8±100.9 MB/s, size: 32.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 178.1±69.1 MB/s, size: 39.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.48G      3.605      18.52      3.695         43        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.373      0.375      0.288      0.145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.48G      2.849      3.305      2.933         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.829      0.804      0.853      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.49G      2.649      2.174      2.691         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.896      0.795      0.897      0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.896      0.796      0.897      0.557\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold2_opt-SGD_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold3/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold3_opt-SGD_lr0.0005_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 199.4±162.4 MB/s, size: 38.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 173.5±41.8 MB/s, size: 39.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.53G      3.639      18.34       3.71         44        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449       0.35      0.352      0.269      0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.49G      2.866      3.294      2.943         36        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.831      0.771      0.845      0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.49G      2.647      2.134      2.687         41        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.877      0.853      0.907      0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.877      0.853      0.907      0.566\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold3_opt-SGD_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold4/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold4_opt-SGD_lr0.0005_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 183.0±123.2 MB/s, size: 36.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 152.5±40.1 MB/s, size: 37.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.49G      3.682      18.46      3.728         43        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.302      0.337      0.256      0.137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.51G      2.831      3.341      2.987         37        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.812      0.726       0.81      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.49G      2.705      2.212      2.731         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.889      0.792      0.878      0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.889      0.793      0.878      0.574\n",
      "Speed: 0.2ms preprocess, 6.6ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold4_opt-SGD_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold0/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold0_opt-AdamW_lr0.001_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 148.7±23.1 MB/s, size: 38.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 197.4±38.1 MB/s, size: 37.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.58G      2.762      6.251      2.794         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.875      0.852      0.904      0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.46G      2.722      1.467      2.614         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.955      0.843       0.95      0.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3       7.5G      2.579      1.216      2.498         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.917      0.897      0.945      0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.915      0.901       0.95      0.605\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold1/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold1_opt-AdamW_lr0.001_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 443.6±339.9 MB/s, size: 39.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 201.4±40.0 MB/s, size: 40.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.53G        2.8      6.312      2.871         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.512      0.636      0.512      0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.51G      2.673       1.71      2.656         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.627      0.751      0.639      0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.46G      2.526       1.35      2.522         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.894      0.849      0.905      0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.894      0.848      0.905      0.577\n",
      "Speed: 0.2ms preprocess, 6.6ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold2/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold2_opt-AdamW_lr0.001_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 180.2±118.9 MB/s, size: 32.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 168.2±52.5 MB/s, size: 39.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.57G      2.795      6.175      2.753         33        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.793      0.767      0.793      0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.49G      2.657      1.488      2.583         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.888      0.819      0.899      0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.49G      2.503      1.223      2.498         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.839      0.889      0.862      0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.889      0.819      0.899      0.543\n",
      "Speed: 0.3ms preprocess, 6.4ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold3/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold3_opt-AdamW_lr0.001_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 146.9±47.9 MB/s, size: 38.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 174.2±49.0 MB/s, size: 39.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.49G      2.766      6.114      2.725         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.834      0.771      0.849      0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.49G      2.681      1.549      2.639         32        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.846       0.83      0.894      0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.52G      2.532      1.333       2.57         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.868      0.851      0.934      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.052 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.869      0.851      0.934      0.578\n",
      "Speed: 0.2ms preprocess, 6.5ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold4/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold4_opt-AdamW_lr0.001_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 182.8±81.5 MB/s, size: 36.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 186.5±44.7 MB/s, size: 37.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.56G      2.753      6.309      2.742         32        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.822      0.766      0.835      0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.51G      2.707       1.62       2.68         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.777      0.759      0.825      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.51G      2.589      1.379      2.606         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.822      0.851      0.889      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.823      0.849      0.889      0.565\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold0/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold0_opt-AdamW_lr0.001_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 114.3±22.4 MB/s, size: 38.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 177.0±72.0 MB/s, size: 37.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      8.54G      2.806      5.321      2.679         41        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.838      0.705      0.835      0.479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.49G      2.792      1.783      2.576         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.813      0.877      0.866       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      8.49G      2.653      1.438      2.497         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.907      0.924       0.95      0.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.052 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.907      0.924       0.95      0.589\n",
      "Speed: 0.2ms preprocess, 6.4ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold1/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold1_opt-AdamW_lr0.001_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 373.0±267.9 MB/s, size: 39.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 200.0±39.6 MB/s, size: 40.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.54G      2.858      4.984      2.707         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437       0.78      0.838      0.867      0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.47G       2.78      1.751      2.589         37        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.907      0.863      0.936      0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      8.47G      2.612      1.495      2.511         38        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.887      0.841      0.902      0.553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.052 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.907      0.863      0.937      0.565\n",
      "Speed: 0.3ms preprocess, 6.4ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold2/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold2_opt-AdamW_lr0.001_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 174.2±59.2 MB/s, size: 32.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 190.6±55.7 MB/s, size: 39.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3       8.5G      2.833      5.146      2.731         43        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.785      0.688      0.774      0.469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.51G      2.797      1.584      2.546         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.892      0.869      0.914      0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3       8.5G       2.66      1.367      2.481         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.912       0.89      0.929      0.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.055 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.912      0.891      0.929      0.589\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold3/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold3_opt-AdamW_lr0.001_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 198.3±104.6 MB/s, size: 38.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 346.9±314.3 MB/s, size: 39.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.54G      2.861      5.189       2.71         44        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.899      0.753      0.841      0.481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3       8.5G      2.781      1.674      2.545         36        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.855      0.826      0.846      0.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.53G       2.63      1.448      2.455         41        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.924      0.893      0.945      0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.053 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.924      0.893      0.945      0.598\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold4/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold4_opt-AdamW_lr0.001_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 151.2±73.7 MB/s, size: 36.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 153.7±45.9 MB/s, size: 37.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.54G      2.879      5.225      2.749         43        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.897      0.784      0.877      0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.52G      2.734      1.732      2.563         37        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.823      0.697      0.774      0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      8.53G      2.633      1.509      2.511         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.841      0.854      0.889      0.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.052 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.842      0.854      0.889      0.538\n",
      "Speed: 0.3ms preprocess, 6.4ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold0/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold0_opt-AdamW_lr0.001_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 177.6±76.1 MB/s, size: 38.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 200.6±39.7 MB/s, size: 37.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3       7.5G      2.765       6.25      2.799         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.879      0.861      0.906      0.499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.51G      2.724      1.458      2.654         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432       0.27      0.747      0.262      0.159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.46G      2.535      1.245       2.49         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.915      0.916       0.95      0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.914      0.919       0.95      0.595\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold1/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold1_opt-AdamW_lr0.001_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 293.8±120.3 MB/s, size: 39.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 203.0±47.7 MB/s, size: 40.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.54G      2.824      6.291      2.917         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.711      0.756       0.79      0.451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.51G      2.655      1.631      2.721         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.827      0.785      0.869      0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.51G      2.499       1.34      2.574         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.845      0.892      0.931      0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.846      0.891      0.931      0.576\n",
      "Speed: 0.2ms preprocess, 6.6ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold2/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold2_opt-AdamW_lr0.001_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 184.2±86.7 MB/s, size: 32.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 195.9±61.0 MB/s, size: 39.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.54G      2.784      6.191      2.752         33        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.808      0.691      0.799      0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.53G       2.67      1.547       2.59         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.899      0.862       0.92      0.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.51G      2.515       1.25       2.52         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.906      0.895      0.925      0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.906      0.895      0.925      0.572\n",
      "Speed: 0.3ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold3/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold3_opt-AdamW_lr0.001_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 188.1±121.0 MB/s, size: 38.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 192.5±37.0 MB/s, size: 39.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.55G      2.749      6.119      2.721         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.785      0.658      0.745       0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.52G      2.693      1.611      2.622         32        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.784      0.784      0.834      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.52G       2.54      1.353       2.56         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.872      0.833      0.909      0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.052 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.872      0.831      0.909      0.561\n",
      "Speed: 0.4ms preprocess, 6.6ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold4/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold4_opt-AdamW_lr0.001_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 172.6±74.6 MB/s, size: 36.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 169.0±65.0 MB/s, size: 37.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.55G      2.748       6.33      2.729         32        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445       0.82       0.73      0.798      0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3       7.5G      2.719       1.67      2.643         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.823      0.813      0.858      0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.51G      2.556      1.393      2.562         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.836      0.804      0.879       0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.836      0.803      0.878       0.56\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold0/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold0_opt-AdamW_lr0.001_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 151.7±31.9 MB/s, size: 38.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 167.0±40.4 MB/s, size: 37.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      8.54G        2.8      5.351      2.689         41        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.639      0.786      0.717      0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.52G      2.797      1.677       2.59         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.796      0.748      0.787      0.457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      8.52G      2.685       1.41      2.513         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.935      0.899      0.957      0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.935      0.899      0.957      0.605\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold1/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold1_opt-AdamW_lr0.001_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 354.6±204.4 MB/s, size: 39.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 201.2±46.8 MB/s, size: 40.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      8.54G      2.846      4.971      2.701         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.871      0.828      0.902      0.524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3       8.5G      2.798      1.777      2.625         37        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.819      0.858      0.905      0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3       8.5G      2.615       1.58      2.531         38        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.929      0.872      0.947      0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.052 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437       0.93      0.872      0.948      0.566\n",
      "Speed: 0.3ms preprocess, 6.3ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold2/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold2_opt-AdamW_lr0.001_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 291.4±220.3 MB/s, size: 32.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 205.7±48.8 MB/s, size: 39.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      8.55G      2.834      5.146      2.731         43        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.766      0.673      0.736      0.446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.52G      2.802      1.627      2.582         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.815      0.835      0.872      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      8.52G      2.635      1.421      2.497         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.862      0.871      0.866      0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.053 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443       0.81      0.835      0.872      0.512\n",
      "Speed: 0.4ms preprocess, 6.4ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold3/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold3_opt-AdamW_lr0.001_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 183.5±118.0 MB/s, size: 38.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 193.1±40.2 MB/s, size: 39.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.54G       2.86      5.194      2.706         44        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.769      0.764      0.758       0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.52G      2.808      1.606      2.586         36        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.879      0.849      0.897      0.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.52G      2.632      1.418      2.487         41        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.911       0.84      0.906      0.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.053 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.911       0.84      0.906      0.568\n",
      "Speed: 0.3ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold4/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold4_opt-AdamW_lr0.001_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 228.8±166.5 MB/s, size: 36.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 186.7±52.2 MB/s, size: 37.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      8.54G       2.87      5.242       2.74         43        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.803      0.768      0.838      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.52G      2.743       1.69      2.576         37        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.872      0.834      0.862      0.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      8.52G      2.629      1.471      2.511         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.915      0.863      0.927      0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.916      0.863      0.927      0.585\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.001_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold0/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold0_opt-AdamW_lr0.0005_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 145.9±9.5 MB/s, size: 38.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 191.1±59.3 MB/s, size: 37.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.54G      2.755      6.347      2.761         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.948       0.85      0.927      0.573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.52G      2.607      1.337      2.504         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.944      0.905      0.951      0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.54G      2.445      1.103      2.393         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.943       0.92      0.972      0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.944      0.919      0.972      0.635\n",
      "Speed: 0.2ms preprocess, 6.4ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold1/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold1_opt-AdamW_lr0.0005_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 175.3±52.1 MB/s, size: 39.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 205.4±44.6 MB/s, size: 40.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.54G      2.753      6.295       2.85         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.797      0.738      0.847      0.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.49G      2.635      1.478      2.612         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.879      0.867      0.936      0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.53G      2.474      1.227      2.452         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.902      0.908      0.954      0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.915      0.899      0.954      0.611\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold2/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold2_opt-AdamW_lr0.0005_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 244.3±197.8 MB/s, size: 32.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 203.9±53.4 MB/s, size: 39.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.57G      2.737      6.206      2.702         33        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.883      0.831      0.904      0.536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.51G      2.613      1.345      2.525         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.914      0.853      0.925      0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.51G      2.464       1.14      2.438         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.952      0.876      0.951      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.953      0.876      0.951      0.623\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold3/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold3_opt-AdamW_lr0.0005_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 227.2±146.7 MB/s, size: 38.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 193.2±43.7 MB/s, size: 39.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.55G      2.733      6.312       2.73         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.702      0.688      0.767      0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.56G      2.614      1.444      2.524         32        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.881      0.835      0.923      0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.49G      2.393      1.261      2.473         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.868      0.869      0.932      0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.868      0.869      0.932      0.592\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold4/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold4_opt-AdamW_lr0.0005_wd0.0001_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0001_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0001_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 201.6±96.3 MB/s, size: 36.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 168.5±69.4 MB/s, size: 37.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0001_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.57G      2.754        6.3      2.763         32        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.806       0.64      0.765      0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.51G      2.607       1.56      2.578         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.842       0.78      0.881      0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      8.46G      2.435      1.311      2.501         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.856      0.867      0.914      0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0001_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0001_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0001_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.856      0.866      0.914      0.588\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0001_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold0/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold0_opt-AdamW_lr0.0005_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 143.1±23.4 MB/s, size: 38.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 196.5±45.1 MB/s, size: 37.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      8.54G      2.742      5.356      2.668         41        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432       0.81      0.757      0.851      0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.52G       2.66      1.629      2.497         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.881      0.891       0.94      0.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      8.48G        2.6      1.412      2.455         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.883       0.93      0.953      0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.881      0.931      0.953      0.604\n",
      "Speed: 0.2ms preprocess, 6.7ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold1/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold1_opt-AdamW_lr0.0005_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 284.4±171.3 MB/s, size: 39.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 165.0±82.7 MB/s, size: 40.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3       7.5G      2.784      5.143      2.732         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.902      0.824      0.919      0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.55G      2.678      1.621      2.517         37        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.888      0.897      0.933      0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      8.55G      2.532      1.457      2.412         38        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.921      0.905      0.959      0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.917      0.913      0.959      0.612\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold2/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold2_opt-AdamW_lr0.0005_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 357.4±363.1 MB/s, size: 32.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 167.4±51.1 MB/s, size: 39.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.54G      2.803      5.249      2.661         43        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.902      0.878      0.925      0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.53G      2.698      1.422      2.453         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.919      0.897      0.946      0.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      8.53G      2.561      1.246      2.397         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.942      0.882      0.936      0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.919      0.899      0.946      0.603\n",
      "Speed: 0.3ms preprocess, 6.5ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold3/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold3_opt-AdamW_lr0.0005_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.1±0.0 ms, read: 175.8±127.2 MB/s, size: 38.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 146.9±28.4 MB/s, size: 39.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.58G       2.78      5.297      2.682         44        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.775      0.706      0.813      0.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.52G      2.651      1.681      2.496         36        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.768      0.804      0.866      0.524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.48G      2.528      1.433      2.423         41        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.872      0.868      0.909      0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.872      0.868      0.909      0.588\n",
      "Speed: 0.2ms preprocess, 6.4ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold4/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold4_opt-AdamW_lr0.0005_wd0.0001_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0001_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0001_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 245.9±242.7 MB/s, size: 36.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 151.6±41.2 MB/s, size: 37.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0001_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0001), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.51G       2.84      5.271      2.715         43        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.859      0.836      0.888       0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.54G      2.664      1.502      2.493         37        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.818       0.84      0.836      0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      8.56G      2.565      1.367      2.459         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445        0.9      0.874       0.92      0.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0001_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0001_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0001_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.899      0.874       0.92       0.58\n",
      "Speed: 0.3ms preprocess, 6.4ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0001_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold0/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold0_opt-AdamW_lr0.0005_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 157.4±29.0 MB/s, size: 38.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 208.2±52.1 MB/s, size: 37.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      8.51G      2.757      6.339      2.765         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.937      0.877      0.934      0.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.53G      2.614      1.346      2.507         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.939      0.898      0.954      0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.48G      2.464      1.119      2.406         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.932      0.924      0.954      0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.048 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.932      0.924      0.954      0.626\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold1/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold1_opt-AdamW_lr0.0005_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 259.5±100.6 MB/s, size: 39.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 211.8±67.3 MB/s, size: 40.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.55G      2.731      6.296       2.84         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.749      0.698      0.788      0.473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.53G      2.585      1.509      2.591         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.838      0.847      0.905      0.559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.48G       2.49      1.289      2.486         28        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.931      0.891       0.95      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.931      0.892       0.95      0.625\n",
      "Speed: 0.3ms preprocess, 6.5ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold2/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold2_opt-AdamW_lr0.0005_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 256.2±173.0 MB/s, size: 32.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 202.6±56.7 MB/s, size: 39.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3       7.5G      2.739      6.204      2.703         33        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.916      0.832       0.92       0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.47G      2.637      1.355      2.534         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.922      0.892      0.947      0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.51G      2.467      1.124      2.444         29        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.946      0.896      0.956      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.946      0.896      0.956      0.642\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold3/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold3_opt-AdamW_lr0.0005_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 267.9±271.3 MB/s, size: 38.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 181.0±50.5 MB/s, size: 39.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.55G       2.73      6.323       2.73         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.707      0.688      0.756      0.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      7.52G      2.594      1.445      2.542         32        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449       0.87      0.879      0.932      0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.48G      2.432      1.216      2.526         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449       0.89      0.857      0.934      0.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449       0.89      0.857      0.934      0.591\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold4/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=fold4_opt-AdamW_lr0.0005_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.1±0.0 ms, read: 173.3±108.2 MB/s, size: 36.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 142.4±38.8 MB/s, size: 37.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0005_mos0/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.56G      2.747      6.306      2.763         32        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.765      0.701      0.777       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3       7.5G      2.616      1.538      2.596         31        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.778      0.843      0.864      0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3       7.5G      2.463      1.258       2.52         30        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.881      0.866      0.928      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.881      0.863      0.928      0.612\n",
      "Speed: 0.2ms preprocess, 6.5ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold0/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold0_opt-AdamW_lr0.0005_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 154.6±11.4 MB/s, size: 38.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 197.7±46.5 MB/s, size: 37.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      8.54G      2.745      5.341      2.673         41        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.803       0.83      0.874      0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.53G      2.658      1.603      2.518         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.928      0.837      0.941      0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      8.55G       2.58      1.464      2.517         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432        0.9      0.875      0.945        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        432      0.902      0.875      0.945        0.6\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold0_opt-AdamW_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold1/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold1_opt-AdamW_lr0.0005_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 588.1±480.3 MB/s, size: 39.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 195.9±45.6 MB/s, size: 40.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3       8.5G      2.781      5.147       2.73         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.883      0.848      0.924      0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.53G      2.695      1.633      2.538         37        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.937      0.889      0.952      0.584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      8.52G      2.548      1.393      2.461         38        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.923      0.927      0.957      0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        424        437      0.924      0.927      0.957      0.606\n",
      "Speed: 0.2ms preprocess, 6.5ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold1_opt-AdamW_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold2/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold2_opt-AdamW_lr0.0005_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 432.9±422.1 MB/s, size: 32.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 197.3±43.4 MB/s, size: 39.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.55G      2.799      5.254      2.662         43        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.906      0.866      0.924      0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.53G      2.669      1.424      2.434         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.945      0.853      0.936      0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      8.52G      2.545      1.254      2.381         40        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.913       0.93      0.936      0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        443      0.913       0.93      0.936      0.592\n",
      "Speed: 0.3ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold2_opt-AdamW_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold3/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold3_opt-AdamW_lr0.0005_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 196.7±96.4 MB/s, size: 38.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 338.4±275.7 MB/s, size: 39.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      7.54G       2.78      5.287      2.679         44        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.681      0.659      0.742      0.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.51G      2.652      1.633      2.463         36        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.875      0.812        0.9      0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      7.52G      2.553      1.459        2.4         41        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.779      0.826      0.876       0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        449      0.779      0.826      0.875      0.549\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold3_opt-AdamW_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=folds/fold4/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=fold4_opt-AdamW_lr0.0005_wd0.0005_mos0.5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov10_cross_validation_hpt, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0005_mos0.5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0005_mos0.5', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 230.8±188.3 MB/s, size: 36.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 190.2±51.3 MB/s, size: 37.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/PROYECTO_5/HYPERPARAMETER_TUNING/folds/f\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0005_mos0.5/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0005_mos0.5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      8.55G       2.84      5.269      2.715         43        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.886      0.816      0.887      0.559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.52G      2.673      1.497      2.517         37        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.854      0.812      0.848        0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      8.52G      2.547      1.354      2.434         35        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.919      0.867      0.935      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.052 hours.\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0005_mos0.5/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0005_mos0.5/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating yolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0005_mos0.5/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        423        445      0.919      0.867      0.935      0.608\n",
      "Speed: 0.3ms preprocess, 6.4ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov10_cross_validation_hpt/fold4_opt-AdamW_lr0.0005_wd0.0005_mos0.5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Generando un folder con  nombre para cada cada experimento especificando los hiperparametros\n",
    "for cfg in grid:\n",
    "    for fold_yaml in fold_paths:\n",
    "        name = (\n",
    "            f\"{Path(fold_yaml).parent.name}\"\n",
    "            f\"_opt-{cfg['optimizer']}\"\n",
    "            f\"_lr{cfg['lr0']}\"\n",
    "            f\"_wd{cfg['weight_decay']}\"\n",
    "            f\"_mos{cfg['mosaic']}\"\n",
    "        )\n",
    "        YOLO(\"yolov10s.pt\").train( # Entremaneiento con el modelo YOLOv10s\n",
    "            data=str(fold_yaml),\n",
    "            project=\"yolov10_cross_validation_hpt\",\n",
    "            name=name,\n",
    "            **cfg,\n",
    "            **params_train\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b1e7db1-9afa-45d6-b83f-77c6235941a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      opt      lr      wd  mos      mean       std  count\n",
      "2   AdamW  0.0005  0.0005    0  0.944558  0.012567      5\n",
      "0   AdamW  0.0005  0.0001    0  0.944364  0.022141      5\n",
      "1   AdamW  0.0005  0.0001  0.5  0.937448  0.021759      5\n",
      "3   AdamW  0.0005  0.0005  0.5  0.934474  0.021331      5\n",
      "5   AdamW   0.001  0.0001  0.5  0.929850  0.024330      5\n",
      "14    SGD   0.001  0.0005    0  0.924334  0.019160      5\n",
      "15    SGD   0.001  0.0005  0.5  0.923842  0.009652      5\n",
      "7   AdamW   0.001  0.0005  0.5  0.921980  0.034257      5\n",
      "12    SGD   0.001  0.0001    0  0.921130  0.014555      5\n",
      "6   AdamW   0.001  0.0005    0  0.918516  0.026764      5\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# LEER TODOS LOS metrics.csv Y AGREGAR POR COMBINACIÓN\n",
    "# -------------------------------------------------------------\n",
    "import glob, re, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT_RUNS = Path(\"yolov10_cross_validation_hpt\")   # carpeta raíz de tus runs\n",
    "pattern   = re.compile(\n",
    "    r\"fold\\d+_\"            # foldX_\n",
    "    r\"opt-(?P<opt>\\w+)_\"\n",
    "    r\"lr(?P<lr>[\\d.]+)_\"\n",
    "    r\"wd(?P<wd>[\\d.]+)_\"\n",
    "    r\"mos(?P<mos>[\\d.]+)\"\n",
    ")  # ← extrae hiperparámetros del nombre de carpeta\n",
    "\n",
    "records = []\n",
    "\n",
    "for csv in ROOT_RUNS.rglob(\"results.csv\"):\n",
    "    run_dir = csv.parent\n",
    "    m = pattern.search(run_dir.name)\n",
    "    if not m:\n",
    "        continue  # ignora carpetas que no sigan el patrón\n",
    "    hp = m.groupdict()                 # dict con opt, lr, wd, mos\n",
    "    df = pd.read_csv(csv)\n",
    "    best_map50 = df[\"metrics/mAP50(B)\"].max()     # mejor época\n",
    "    fold       = run_dir.name.split(\"_\")[0]     # fold0, fold1…\n",
    "    records.append({**hp, \"fold\": fold, \"mAP50\": best_map50})\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# PROMEDIAR Y CALCULAR (media ± std) POR COMBINACIÓN\n",
    "# -------------------------------------------------------------\n",
    "df = pd.DataFrame(records)\n",
    "group_cols = [\"opt\", \"lr\", \"wd\", \"mos\"]\n",
    "summary = (\n",
    "    df.groupby(group_cols)[\"mAP50\"]\n",
    "      .agg([\"mean\", \"std\", \"count\"])\n",
    "      .reset_index()\n",
    "      .sort_values(\"mean\", ascending=False)\n",
    ")\n",
    "print(summary.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344d6366-e0c6-4c59-b3f3-fbc15ba34f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.170 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/Users/pepefv97/Downloads/DATOS_PLACAS/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=0, multi_scale=False, name=YOLOV10S_AdamW_lr0.0005_wd0.0005_mos0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=ENTRENAMIENTO_YOLOV10S, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=ENTRENAMIENTO_YOLOV10S/YOLOV10S_AdamW_lr0.0005_wd0.0005_mos0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,067,126 parameters, 8,067,110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ENTRENAMIENTO_YOLOV10S/YOLOV10S_AdamW_lr0.0005_wd0.0005_mos0', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.cv1.conv.weight'\n",
      "Freezing layer 'model.5.cv1.bn.weight'\n",
      "Freezing layer 'model.5.cv1.bn.bias'\n",
      "Freezing layer 'model.5.cv2.conv.weight'\n",
      "Freezing layer 'model.5.cv2.bn.weight'\n",
      "Freezing layer 'model.5.cv2.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.cv1.conv.weight'\n",
      "Freezing layer 'model.7.cv1.bn.weight'\n",
      "Freezing layer 'model.7.cv1.bn.bias'\n",
      "Freezing layer 'model.7.cv2.conv.weight'\n",
      "Freezing layer 'model.7.cv2.bn.weight'\n",
      "Freezing layer 'model.7.cv2.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.0.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.0.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.2.conv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.4.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.4.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 95.8±26.7 MB/s, size: 43.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/pepefv97/Downloads/DATOS_PLACAS/train/labels.cache... 211\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 121.5±47.2 MB/s, size: 35.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/pepefv97/Downloads/DATOS_PLACAS/valid/labels.cache... 2046 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to ENTRENAMIENTO_YOLOV10S/YOLOV10S_AdamW_lr0.0005_wd0.0005_mos0/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mENTRENAMIENTO_YOLOV10S/YOLOV10S_AdamW_lr0.0005_wd0.0005_mos0\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      7.48G      2.514      1.558       2.45         22        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2046       2132      0.931      0.909      0.957      0.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      7.31G      2.396      1.033      2.362         24        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2046       2132       0.94      0.928      0.964      0.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      7.37G      2.308     0.9382      2.306         21        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2046       2132      0.961      0.924      0.975       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      7.31G      2.247      0.892      2.276         21        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2046       2132      0.952      0.941      0.977      0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      7.31G      2.183     0.8397      2.235         21        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2046       2132      0.959       0.92      0.975      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      7.29G      2.121     0.7824      2.203         23        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2046       2132       0.96      0.938       0.98      0.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      7.31G       2.07     0.7432       2.17         21        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2046       2132      0.972      0.949      0.981      0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      7.31G      2.021     0.7087      2.144         22        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2046       2132      0.967      0.957      0.983        0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      7.29G      1.954     0.6708      2.109         22        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2046       2132      0.973      0.952      0.983      0.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      7.29G      1.894     0.6371      2.078         20        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2046       2132      0.967      0.962      0.984      0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 3.145 hours.\n",
      "Optimizer stripped from ENTRENAMIENTO_YOLOV10S/YOLOV10S_AdamW_lr0.0005_wd0.0005_mos0/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from ENTRENAMIENTO_YOLOV10S/YOLOV10S_AdamW_lr0.0005_wd0.0005_mos0/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating ENTRENAMIENTO_YOLOV10S/YOLOV10S_AdamW_lr0.0005_wd0.0005_mos0/weights/best.pt...\n",
      "Ultralytics 8.3.169 🚀 Python-3.12.2 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "YOLOv10s summary (fused): 106 layers, 7,218,387 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2046       2132      0.967      0.963      0.984      0.705\n",
      "Speed: 0.4ms preprocess, 10.8ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mENTRENAMIENTO_YOLOV10S/YOLOV10S_AdamW_lr0.0005_wd0.0005_mos0\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x37b01a360>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,\n",
       "            0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,\n",
       "            0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,\n",
       "            0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,\n",
       "            0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99853,     0.99853,     0.99853,     0.99853,     0.99853,     0.99853,     0.99853,     0.99853,     0.99853,     0.99853,     0.99853,\n",
       "            0.99853,     0.99853,     0.99853,     0.99853,     0.99853,     0.99853,     0.99853,     0.99853,     0.99853,     0.99853,     0.99853,     0.99853,     0.99853,     0.99853,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,\n",
       "            0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,\n",
       "            0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,\n",
       "            0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,\n",
       "            0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,\n",
       "            0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,\n",
       "            0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,\n",
       "            0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,     0.99823,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,\n",
       "             0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,\n",
       "             0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,      0.9978,\n",
       "            0.99729,     0.99729,     0.99729,     0.99729,     0.99729,     0.99729,     0.99729,     0.99729,     0.99729,     0.99729,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,\n",
       "            0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99633,     0.99633,     0.99582,     0.99582,     0.99582,     0.99582,     0.99531,     0.99485,\n",
       "            0.99485,     0.99485,     0.99485,     0.99485,     0.99485,     0.99485,     0.99485,     0.99485,     0.99485,     0.99438,     0.99438,     0.99438,     0.99438,     0.99438,     0.99438,     0.99337,     0.99287,     0.99237,      0.9914,      0.9914,      0.9914,     0.99094,     0.99094,\n",
       "            0.99094,     0.99094,     0.99094,     0.99047,     0.99047,     0.99047,     0.98949,     0.98901,     0.98804,     0.98665,     0.98665,     0.98665,     0.98665,     0.98665,     0.98665,     0.98619,     0.98619,     0.98474,     0.98284,     0.98284,      0.9819,     0.98144,     0.98098,\n",
       "            0.98004,      0.9796,      0.9796,     0.97868,     0.97728,     0.97542,     0.97404,      0.9736,      0.9727,     0.97178,      0.9714,      0.9714,     0.97095,     0.96961,     0.96917,     0.96874,     0.96788,     0.96788,     0.96747,     0.96432,     0.95985,     0.95857,     0.95598,\n",
       "            0.95598,     0.95247,      0.9464,     0.93702,     0.93499,     0.93127,     0.92927,     0.92848,     0.92113,     0.90596,     0.89361,     0.86592,     0.84058,     0.80446,     0.78206,     0.71885,     0.66162,     0.52254,     0.46709,     0.43595,     0.40481,     0.37367,     0.34253,\n",
       "            0.31139,     0.28025,     0.24912,     0.21798,     0.18684,      0.1557,     0.12456,    0.093418,    0.062279,    0.031139,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.65964,     0.65968,     0.73735,     0.77649,     0.80294,     0.82001,     0.83179,     0.84038,     0.85082,     0.85839,     0.86379,     0.87031,     0.87453,      0.8784,      0.8829,     0.88668,     0.89045,     0.89296,     0.89614,     0.89756,     0.89863,     0.90183,     0.90373,\n",
       "            0.90527,     0.90699,     0.90903,     0.90989,     0.91073,     0.91197,     0.91345,     0.91457,     0.91634,     0.91752,     0.91858,     0.91986,     0.92065,     0.92087,     0.92167,     0.92241,     0.92279,      0.9235,     0.92474,     0.92552,     0.92597,     0.92683,     0.92729,\n",
       "            0.92811,     0.92846,     0.92894,      0.9294,      0.9298,     0.93052,     0.93073,     0.93149,     0.93238,     0.93313,     0.93339,     0.93345,     0.93365,     0.93397,     0.93483,     0.93604,     0.93716,     0.93759,     0.93774,     0.93807,      0.9382,     0.93858,     0.93902,\n",
       "            0.93924,     0.93947,     0.93983,     0.94029,     0.94114,     0.94134,     0.94174,     0.94227,     0.94291,     0.94306,     0.94322,     0.94309,      0.9432,     0.94334,     0.94349,      0.9438,     0.94415,     0.94442,     0.94474,     0.94564,     0.94615,     0.94625,     0.94653,\n",
       "            0.94682,     0.94723,     0.94731,     0.94716,     0.94736,     0.94742,     0.94748,     0.94753,     0.94765,     0.94781,     0.94797,     0.94854,     0.94889,      0.9492,     0.94933,     0.94953,     0.94983,     0.95007,     0.95073,     0.95064,     0.95086,     0.95097,     0.95068,\n",
       "            0.95059,     0.95051,     0.95069,     0.95087,     0.95108,     0.95093,     0.95124,     0.95133,     0.95146,     0.95152,     0.95143,     0.95133,     0.95143,     0.95179,     0.95191,     0.95202,      0.9521,     0.95225,     0.95277,     0.95272,     0.95253,      0.9523,     0.95213,\n",
       "            0.95215,     0.95217,     0.95219,     0.95221,     0.95223,     0.95225,     0.95227,     0.95229,     0.95231,     0.95233,     0.95254,     0.95269,     0.95284,     0.95299,     0.95318,     0.95322,     0.95332,     0.95341,     0.95347,     0.95353,     0.95359,      0.9537,     0.95398,\n",
       "            0.95432,     0.95439,     0.95447,     0.95459,     0.95503,     0.95508,     0.95495,     0.95503,     0.95511,     0.95544,     0.95563,     0.95569,     0.95575,     0.95581,     0.95593,     0.95604,     0.95643,     0.95663,     0.95678,     0.95692,      0.9571,     0.95759,     0.95743,\n",
       "            0.95743,     0.95757,     0.95761,     0.95765,     0.95769,     0.95773,     0.95777,     0.95783,     0.95791,     0.95798,      0.9582,      0.9583,     0.95837,     0.95844,      0.9584,     0.95833,     0.95825,     0.95832,     0.95848,     0.95859,     0.95867,      0.9587,     0.95874,\n",
       "            0.95877,      0.9588,     0.95884,     0.95887,     0.95896,     0.95915,     0.95937,     0.95943,     0.95948,     0.95953,      0.9598,     0.95989,     0.95999,     0.96021,     0.96002,     0.96006,     0.96011,     0.96015,     0.96019,     0.96027,     0.96036,     0.96048,     0.96066,\n",
       "            0.96082,     0.96105,     0.96134,     0.96151,     0.96173,     0.96167,      0.9616,     0.96154,     0.96142,      0.9613,      0.9612,     0.96109,     0.96086,     0.96126,      0.9613,     0.96135,     0.96139,     0.96144,     0.96172,     0.96196,     0.96202,     0.96209,     0.96213,\n",
       "            0.96193,     0.96186,      0.9618,     0.96174,     0.96168,     0.96171,     0.96177,     0.96183,     0.96189,     0.96197,     0.96206,     0.96189,     0.96194,       0.962,     0.96205,      0.9621,     0.96223,     0.96224,     0.96212,      0.9623,     0.96236,     0.96241,     0.96247,\n",
       "            0.96259,      0.9628,     0.96291,     0.96299,     0.96303,     0.96308,     0.96312,     0.96317,     0.96323,      0.9633,     0.96336,     0.96343,      0.9635,     0.96356,     0.96363,     0.96365,     0.96366,     0.96367,     0.96368,     0.96368,     0.96369,      0.9637,     0.96371,\n",
       "            0.96372,     0.96373,     0.96374,     0.96375,     0.96376,     0.96377,     0.96378,     0.96379,      0.9638,     0.96381,     0.96381,     0.96382,     0.96383,     0.96384,     0.96385,     0.96386,     0.96369,     0.96398,     0.96413,     0.96422,     0.96431,     0.96436,     0.96441,\n",
       "            0.96446,     0.96451,     0.96476,     0.96478,      0.9648,     0.96482,     0.96483,     0.96485,     0.96487,     0.96489,     0.96491,     0.96492,     0.96494,     0.96496,     0.96498,     0.96475,     0.96494,     0.96469,     0.96462,     0.96455,     0.96448,     0.96438,     0.96428,\n",
       "            0.96432,     0.96443,      0.9642,     0.96414,     0.96409,     0.96403,     0.96394,     0.96386,      0.9639,     0.96383,     0.96376,     0.96372,     0.96375,     0.96377,      0.9638,     0.96382,     0.96385,     0.96387,      0.9639,     0.96393,      0.9639,     0.96379,     0.96369,\n",
       "            0.96365,     0.96362,     0.96358,     0.96354,      0.9635,     0.96347,     0.96364,     0.96348,     0.96364,     0.96361,     0.96358,     0.96355,     0.96352,     0.96349,     0.96346,     0.96343,     0.96338,     0.96332,     0.96326,      0.9632,     0.96319,     0.96321,     0.96324,\n",
       "            0.96326,     0.96329,     0.96331,     0.96334,     0.96336,     0.96339,     0.96362,     0.96347,     0.96343,     0.96352,     0.96358,     0.96344,     0.96355,     0.96334,     0.96332,     0.96329,     0.96326,     0.96323,      0.9632,     0.96317,     0.96314,     0.96312,     0.96309,\n",
       "            0.96307,     0.96305,     0.96303,     0.96301,     0.96299,     0.96297,     0.96295,     0.96293,     0.96291,     0.96289,     0.96287,     0.96283,     0.96276,     0.96269,     0.96262,     0.96254,     0.96245,     0.96237,      0.9622,     0.96226,     0.96246,     0.96247,     0.96235,\n",
       "            0.96228,     0.96222,     0.96216,     0.96211,     0.96208,      0.9621,     0.96213,     0.96216,     0.96219,     0.96222,     0.96225,     0.96227,     0.96227,     0.96215,      0.9621,     0.96217,     0.96202,     0.96188,     0.96184,     0.96197,     0.96192,     0.96177,     0.96185,\n",
       "            0.96193,     0.96202,     0.96213,     0.96216,     0.96215,     0.96207,     0.96199,     0.96209,     0.96204,     0.96209,     0.96221,     0.96227,     0.96234,      0.9624,     0.96243,     0.96245,     0.96248,     0.96251,     0.96254,     0.96257,     0.96259,     0.96262,     0.96256,\n",
       "            0.96246,     0.96236,     0.96226,     0.96217,     0.96239,     0.96282,     0.96263,     0.96252,     0.96245,     0.96238,     0.96241,     0.96249,     0.96239,     0.96232,     0.96235,     0.96239,     0.96243,     0.96246,      0.9625,     0.96253,     0.96228,     0.96219,     0.96209,\n",
       "              0.962,      0.9619,      0.9618,     0.96156,     0.96162,     0.96167,     0.96173,     0.96168,     0.96157,     0.96163,     0.96168,     0.96174,     0.96181,      0.9619,     0.96199,     0.96191,     0.96184,     0.96176,     0.96149,     0.96143,     0.96137,     0.96131,     0.96125,\n",
       "            0.96145,     0.96143,      0.9614,     0.96138,     0.96135,     0.96133,      0.9613,     0.96128,     0.96125,     0.96123,     0.96117,      0.9611,     0.96104,     0.96098,     0.96099,       0.961,     0.96102,     0.96103,     0.96104,     0.96106,     0.96107,     0.96108,     0.96109,\n",
       "            0.96111,     0.96112,     0.96113,     0.96115,     0.96116,     0.96117,     0.96118,      0.9612,     0.96116,       0.961,     0.96089,      0.9608,     0.96071,     0.96078,     0.96086,     0.96094,       0.961,     0.96105,      0.9611,     0.96116,     0.96115,     0.96112,     0.96109,\n",
       "            0.96107,     0.96104,     0.96101,     0.96098,     0.96096,     0.96093,     0.96065,      0.9606,     0.96054,     0.96048,     0.96043,     0.96031,     0.96019,     0.96026,     0.96037,     0.96052,     0.96045,     0.96064,     0.96079,     0.96072,     0.96087,     0.96096,     0.96105,\n",
       "            0.96126,     0.96124,     0.96118,     0.96113,     0.96107,      0.9609,     0.96069,     0.96054,     0.96039,     0.96034,     0.96051,     0.96016,     0.96002,     0.95985,     0.95958,     0.95933,     0.95923,     0.95917,     0.95912,     0.95906,     0.95897,     0.95864,     0.95841,\n",
       "            0.95828,      0.9582,     0.95812,     0.95804,     0.95793,     0.95779,     0.95726,     0.95769,     0.95788,     0.95774,     0.95749,     0.95754,     0.95766,     0.95756,     0.95764,     0.95759,     0.95755,     0.95751,     0.95747,     0.95743,     0.95737,     0.95729,     0.95722,\n",
       "            0.95716,     0.95719,     0.95723,     0.95727,     0.95731,     0.95735,     0.95738,     0.95735,     0.95732,     0.95729,     0.95725,     0.95722,     0.95719,     0.95716,     0.95689,     0.95712,     0.95718,     0.95724,      0.9573,     0.95725,     0.95707,     0.95703,     0.95699,\n",
       "            0.95695,     0.95691,     0.95687,     0.95683,     0.95678,     0.95673,     0.95668,     0.95663,     0.95658,     0.95651,     0.95643,     0.95636,     0.95622,     0.95604,      0.9559,     0.95565,     0.95565,     0.95576,     0.95562,     0.95547,     0.95537,     0.95525,     0.95505,\n",
       "            0.95465,     0.95423,     0.95401,     0.95395,     0.95388,     0.95381,     0.95368,     0.95356,     0.95372,     0.95355,     0.95295,     0.95273,     0.95235,     0.95197,     0.95209,     0.95195,     0.95203,     0.95212,     0.95203,     0.95181,     0.95167,     0.95181,     0.95186,\n",
       "            0.95177,     0.95169,     0.95158,     0.95143,     0.95139,     0.95178,     0.95128,     0.95116,     0.95099,     0.95022,     0.95008,     0.94967,     0.94941,     0.94912,     0.94833,     0.94833,     0.94812,     0.94798,     0.94752,      0.9464,     0.94586,     0.94575,     0.94564,\n",
       "             0.9452,     0.94471,     0.94432,      0.9439,     0.94332,      0.9429,     0.94277,     0.94256,     0.94213,     0.94192,     0.94152,     0.94116,     0.94077,     0.94075,      0.9401,     0.93966,     0.93945,      0.9394,     0.93935,     0.93931,     0.93926,      0.9391,     0.93862,\n",
       "            0.93848,     0.93801,     0.93734,     0.93715,     0.93699,     0.93681,     0.93648,      0.9363,     0.93611,      0.9354,     0.93443,     0.93398,     0.93349,     0.93305,     0.93282,     0.93164,     0.93092,     0.93053,     0.93021,     0.92995,      0.9292,     0.92872,     0.92828,\n",
       "            0.92744,     0.92723,     0.92705,     0.92657,     0.92629,     0.92572,     0.92451,     0.92435,     0.92369,     0.92317,     0.92264,     0.92161,     0.92113,      0.9208,     0.92029,     0.91941,     0.91886,     0.91697,     0.91641,     0.91534,     0.91403,     0.91223,     0.91127,\n",
       "            0.90862,     0.90725,     0.90632,     0.90573,      0.9041,      0.9018,     0.90149,     0.90054,     0.89894,     0.89812,     0.89671,     0.89447,     0.89308,     0.89188,     0.89077,     0.89021,      0.8891,     0.88842,     0.88603,     0.88419,     0.88292,     0.88058,      0.8799,\n",
       "            0.87869,     0.87663,     0.87575,      0.8746,       0.873,     0.87203,     0.87069,     0.86836,     0.86682,     0.86529,     0.86226,     0.86033,     0.85984,     0.85727,      0.8543,     0.85266,     0.84965,     0.84814,     0.84605,     0.84447,     0.84023,     0.83668,      0.8334,\n",
       "            0.82962,     0.82601,     0.82248,     0.81601,     0.81181,     0.80736,     0.80221,      0.7962,     0.78721,     0.77962,     0.77478,       0.765,     0.75721,     0.74799,     0.73574,     0.72624,     0.71728,     0.70542,     0.69441,     0.68222,      0.6679,      0.6522,     0.64141,\n",
       "            0.63067,     0.61662,       0.604,     0.59204,     0.57555,     0.55899,     0.54173,     0.53483,     0.51623,     0.49957,     0.48323,     0.47603,     0.46684,     0.45975,     0.45454,     0.44828,     0.44305,     0.43217,     0.42733,      0.4235,     0.42205,     0.41758,     0.41249,\n",
       "            0.40742,     0.40435,     0.40081,     0.39447,     0.39065,     0.38713,     0.38014,     0.37078,     0.35251,     0.33802,     0.32769,     0.31427,     0.29768,     0.28292,     0.26336,     0.24245,       0.227,     0.20508,     0.18283,     0.16073,      0.1466,     0.12966,     0.11647,\n",
       "            0.10391,    0.084657,    0.076563,     0.07014,    0.065309,    0.058642,    0.052287,    0.050949,    0.048733,    0.047452,    0.046422,    0.045995,    0.045015,    0.043129,    0.042634,    0.041955,    0.040945,    0.040133,    0.039414,    0.039124,    0.038835,    0.038578,    0.038392,\n",
       "           0.038205,    0.038018,    0.037831,    0.035865,    0.034799,    0.031856,    0.031104,    0.029297,    0.027504,    0.025859,    0.025273,    0.024411,    0.023918,    0.023667,    0.023415,    0.023014,    0.021281,    0.020564,    0.019641,    0.018034,    0.016421,    0.015421,    0.014728,\n",
       "           0.014316,    0.013675,    0.012589,    0.011133,     0.01085,    0.010567,    0.010285,   0.0096164,   0.0089235,   0.0079692,   0.0069677,   0.0063686,   0.0059336,   0.0049206,   0.0042654,   0.0038096,   0.0032174,   0.0025348,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[     0.4961,     0.49614,     0.58989,     0.64164,     0.67903,     0.70381,      0.7216,     0.73463,     0.75072,      0.7626,     0.77115,     0.78192,     0.78906,     0.79568,      0.8031,      0.8097,     0.81601,     0.82024,     0.82563,     0.82803,     0.83019,     0.83567,     0.83894,\n",
       "            0.84194,     0.84493,     0.84847,     0.84997,     0.85143,     0.85362,      0.8562,     0.85853,     0.86167,     0.86376,     0.86588,     0.86837,     0.87007,     0.87046,     0.87188,     0.87321,     0.87389,     0.87516,     0.87777,     0.87919,     0.87998,     0.88154,     0.88238,\n",
       "            0.88386,     0.88451,     0.88538,     0.88621,     0.88694,     0.88825,     0.88862,     0.89002,     0.89164,     0.89302,     0.89349,     0.89399,     0.89436,     0.89494,     0.89654,     0.89875,      0.9009,     0.90201,      0.9023,     0.90292,     0.90315,     0.90386,     0.90466,\n",
       "            0.90508,     0.90551,     0.90659,     0.90743,     0.90902,     0.90939,     0.91014,     0.91113,     0.91232,     0.91261,     0.91307,     0.91305,     0.91328,     0.91355,     0.91382,     0.91441,     0.91506,     0.91558,     0.91618,     0.91786,     0.91883,     0.91902,     0.91955,\n",
       "            0.92009,     0.92087,     0.92113,      0.9211,     0.92153,     0.92164,     0.92176,     0.92187,     0.92209,     0.92239,      0.9227,     0.92378,     0.92444,     0.92502,     0.92569,     0.92607,     0.92664,     0.92711,     0.92847,     0.92861,     0.92904,     0.92924,     0.92923,\n",
       "            0.92922,     0.92921,     0.92957,      0.9299,     0.93031,     0.93043,     0.93125,     0.93165,      0.9319,     0.93207,     0.93206,     0.93205,     0.93227,     0.93296,      0.9332,      0.9334,     0.93357,     0.93384,     0.93485,     0.93497,     0.93495,     0.93492,     0.93492,\n",
       "            0.93496,       0.935,     0.93504,     0.93508,     0.93512,     0.93516,      0.9352,     0.93523,     0.93527,     0.93531,     0.93571,     0.93601,      0.9363,     0.93659,     0.93695,     0.93747,     0.93765,     0.93784,     0.93795,     0.93806,     0.93817,      0.9384,     0.93893,\n",
       "             0.9396,     0.93974,     0.93988,     0.94011,     0.94098,     0.94125,     0.94126,     0.94142,     0.94158,     0.94221,     0.94259,     0.94271,     0.94282,     0.94294,     0.94316,     0.94338,     0.94414,     0.94452,     0.94483,     0.94509,     0.94544,      0.9464,     0.94639,\n",
       "            0.94654,     0.94682,      0.9469,     0.94698,     0.94705,     0.94713,     0.94721,     0.94732,     0.94747,     0.94762,     0.94806,     0.94824,     0.94838,     0.94852,     0.94855,     0.94854,     0.94853,     0.94874,     0.94905,     0.94925,     0.94942,     0.94948,     0.94955,\n",
       "            0.94961,     0.94968,     0.94974,     0.94981,     0.94999,     0.95036,      0.9508,      0.9509,     0.95101,     0.95112,     0.95163,     0.95182,       0.952,     0.95244,     0.95252,     0.95261,     0.95269,     0.95278,     0.95286,     0.95302,      0.9532,     0.95343,     0.95378,\n",
       "            0.95409,     0.95456,     0.95512,     0.95546,     0.95597,     0.95597,     0.95596,     0.95596,     0.95595,     0.95594,     0.95593,     0.95592,      0.9559,      0.9568,     0.95689,     0.95698,     0.95707,     0.95716,     0.95771,     0.95819,     0.95832,     0.95845,     0.95856,\n",
       "            0.95855,     0.95854,     0.95854,     0.95853,     0.95853,     0.95861,     0.95873,     0.95885,     0.95897,     0.95914,     0.95931,     0.95943,     0.95954,     0.95966,     0.95977,     0.96032,     0.96059,     0.96072,     0.96072,     0.96119,      0.9613,     0.96141,     0.96152,\n",
       "            0.96176,     0.96218,      0.9624,     0.96256,     0.96265,     0.96274,     0.96283,     0.96292,     0.96304,     0.96318,     0.96331,     0.96345,     0.96358,     0.96371,     0.96384,     0.96388,      0.9639,     0.96392,     0.96394,     0.96396,     0.96397,     0.96399,     0.96401,\n",
       "            0.96403,     0.96405,     0.96407,     0.96409,      0.9641,     0.96412,     0.96414,     0.96416,     0.96418,      0.9642,     0.96422,     0.96423,     0.96425,     0.96427,     0.96429,     0.96431,     0.96431,     0.96501,     0.96532,     0.96551,     0.96568,     0.96578,     0.96587,\n",
       "            0.96597,     0.96607,     0.96658,     0.96662,     0.96666,     0.96669,     0.96673,     0.96677,      0.9668,     0.96684,     0.96688,     0.96691,     0.96695,     0.96698,     0.96702,     0.96703,     0.96742,     0.96745,     0.96745,     0.96744,     0.96744,     0.96743,     0.96743,\n",
       "            0.96759,     0.96788,     0.96786,     0.96786,     0.96786,     0.96785,     0.96785,     0.96809,     0.96829,     0.96828,     0.96828,      0.9683,     0.96835,      0.9684,     0.96845,      0.9685,     0.96855,      0.9686,     0.96865,      0.9687,     0.96873,     0.96873,     0.96872,\n",
       "            0.96872,     0.96872,     0.96871,     0.96871,     0.96871,     0.96871,      0.9691,     0.96924,     0.96961,     0.96961,     0.96961,      0.9696,      0.9696,      0.9696,      0.9696,      0.9696,     0.96959,     0.96959,     0.96959,     0.96958,     0.96961,     0.96966,     0.96971,\n",
       "            0.96976,     0.96981,     0.96986,     0.96991,     0.96996,     0.97001,      0.9705,     0.97049,     0.97058,     0.97077,     0.97095,     0.97109,     0.97131,     0.97139,     0.97139,     0.97138,     0.97138,     0.97138,     0.97138,     0.97138,     0.97138,     0.97137,     0.97137,\n",
       "            0.97137,     0.97137,     0.97137,     0.97137,     0.97137,     0.97137,     0.97137,     0.97136,     0.97136,     0.97136,     0.97136,     0.97136,     0.97135,     0.97135,     0.97135,     0.97134,     0.97134,     0.97133,     0.97132,     0.97161,     0.97251,      0.9727,     0.97269,\n",
       "            0.97269,     0.97268,     0.97268,     0.97268,     0.97269,     0.97275,     0.97281,     0.97287,     0.97292,     0.97298,     0.97304,      0.9731,     0.97314,     0.97313,     0.97323,     0.97359,     0.97358,     0.97358,     0.97367,     0.97394,     0.97403,     0.97403,      0.9742,\n",
       "            0.97436,     0.97454,     0.97476,     0.97496,     0.97542,     0.97542,     0.97541,     0.97567,     0.97587,     0.97618,     0.97642,     0.97655,     0.97668,     0.97681,     0.97687,     0.97693,     0.97698,     0.97704,      0.9771,     0.97715,     0.97721,     0.97727,     0.97728,\n",
       "            0.97728,     0.97727,     0.97727,     0.97726,      0.9778,     0.97868,     0.97867,     0.97867,     0.97867,     0.97866,     0.97883,     0.97913,     0.97913,     0.97915,     0.97922,     0.97929,     0.97937,     0.97944,     0.97952,     0.97959,     0.97959,     0.97959,     0.97958,\n",
       "            0.97958,     0.97958,     0.97957,      0.9796,     0.97971,     0.97982,     0.97994,     0.98004,     0.98012,     0.98024,     0.98035,     0.98047,     0.98062,      0.9808,     0.98098,     0.98098,     0.98098,     0.98098,     0.98097,     0.98096,     0.98096,     0.98096,     0.98096,\n",
       "            0.98144,     0.98143,     0.98143,     0.98143,     0.98143,     0.98143,     0.98143,     0.98143,     0.98143,     0.98143,     0.98143,     0.98142,     0.98142,     0.98142,     0.98145,     0.98147,      0.9815,     0.98153,     0.98155,     0.98158,     0.98161,     0.98164,     0.98166,\n",
       "            0.98169,     0.98172,     0.98174,     0.98177,      0.9818,     0.98182,     0.98185,     0.98188,      0.9819,     0.98189,     0.98189,     0.98188,     0.98188,     0.98204,     0.98221,     0.98237,     0.98248,     0.98259,     0.98271,     0.98282,     0.98284,     0.98284,     0.98284,\n",
       "            0.98284,     0.98284,     0.98284,     0.98284,     0.98284,     0.98283,     0.98283,     0.98282,     0.98282,     0.98282,     0.98282,     0.98281,     0.98281,     0.98299,     0.98322,     0.98377,      0.9839,      0.9843,     0.98463,     0.98498,      0.9853,     0.98549,     0.98568,\n",
       "            0.98613,     0.98619,     0.98618,     0.98618,     0.98618,     0.98618,     0.98617,     0.98617,     0.98616,     0.98627,     0.98662,     0.98664,     0.98663,     0.98663,     0.98662,     0.98662,     0.98661,     0.98661,     0.98661,     0.98661,     0.98661,      0.9866,     0.98659,\n",
       "            0.98659,     0.98659,     0.98658,     0.98658,     0.98658,     0.98657,     0.98656,     0.98749,     0.98789,     0.98803,     0.98803,     0.98822,     0.98847,     0.98879,     0.98901,       0.989,       0.989,       0.989,       0.989,       0.989,       0.989,       0.989,       0.989,\n",
       "              0.989,     0.98908,     0.98916,     0.98924,     0.98932,     0.98941,     0.98949,     0.98949,     0.98949,     0.98949,     0.98949,     0.98949,     0.98949,     0.98948,      0.9895,     0.98999,     0.99012,     0.99025,     0.99038,     0.99047,     0.99047,     0.99047,     0.99046,\n",
       "            0.99046,     0.99046,     0.99046,     0.99046,     0.99046,     0.99046,     0.99046,     0.99046,     0.99046,     0.99046,     0.99045,     0.99045,     0.99045,     0.99045,     0.99044,     0.99044,     0.99062,     0.99084,     0.99093,     0.99093,     0.99093,     0.99093,     0.99092,\n",
       "            0.99092,     0.99091,      0.9909,      0.9909,      0.9909,      0.9909,      0.9909,     0.99098,     0.99133,     0.99139,     0.99138,     0.99138,     0.99137,     0.99139,     0.99164,     0.99188,     0.99207,     0.99225,     0.99237,     0.99236,     0.99239,     0.99269,     0.99287,\n",
       "            0.99287,     0.99287,     0.99286,     0.99286,     0.99344,     0.99438,     0.99437,     0.99437,     0.99437,     0.99436,     0.99436,     0.99435,     0.99435,     0.99435,     0.99434,     0.99485,     0.99485,     0.99485,     0.99484,     0.99483,     0.99482,     0.99482,     0.99482,\n",
       "            0.99482,     0.99481,     0.99481,      0.9948,     0.99492,     0.99531,     0.99531,     0.99554,     0.99582,     0.99582,     0.99581,     0.99581,     0.99581,     0.99633,     0.99632,     0.99684,     0.99684,     0.99684,     0.99684,     0.99684,     0.99684,     0.99684,     0.99684,\n",
       "            0.99684,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99682,     0.99682,     0.99682,     0.99682,     0.99681,     0.99681,      0.9968,      0.9968,      0.9968,     0.99679,     0.99679,     0.99678,     0.99678,     0.99678,     0.99678,     0.99677,     0.99677,\n",
       "            0.99677,     0.99676,     0.99676,     0.99676,     0.99676,     0.99675,     0.99675,     0.99728,     0.99728,     0.99728,     0.99728,     0.99727,     0.99727,     0.99727,     0.99726,     0.99726,     0.99741,     0.99779,     0.99779,     0.99779,     0.99778,     0.99777,     0.99777,\n",
       "            0.99776,     0.99775,     0.99775,     0.99774,     0.99774,     0.99772,     0.99772,     0.99772,     0.99771,     0.99771,      0.9977,     0.99769,     0.99768,     0.99768,     0.99767,     0.99767,     0.99767,     0.99766,     0.99765,     0.99764,     0.99823,     0.99822,     0.99821,\n",
       "            0.99821,      0.9982,      0.9982,      0.9982,     0.99819,     0.99819,     0.99818,     0.99817,     0.99817,     0.99816,     0.99815,     0.99814,     0.99814,     0.99813,     0.99812,     0.99811,      0.9981,      0.9981,     0.99809,     0.99808,     0.99806,     0.99805,     0.99804,\n",
       "            0.99802,     0.99801,     0.99799,     0.99797,     0.99795,     0.99793,     0.99791,     0.99788,     0.99784,     0.99781,     0.99852,     0.99849,     0.99874,     0.99922,      0.9992,     0.99918,     0.99916,     0.99914,     0.99912,      0.9991,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.98405,     0.98405,     0.98311,     0.98311,     0.98218,     0.98218,     0.98171,     0.98171,     0.98171,     0.98171,     0.98171,     0.98124,     0.98077,      0.9803,      0.9803,     0.97983,     0.97983,     0.97983,     0.97983,     0.97983,     0.97936,     0.97936,     0.97936,\n",
       "            0.97889,     0.97889,     0.97889,     0.97889,     0.97889,     0.97889,     0.97889,     0.97842,     0.97842,     0.97842,      0.9781,     0.97784,     0.97749,     0.97749,     0.97749,     0.97749,     0.97749,     0.97749,     0.97702,     0.97702,     0.97702,     0.97702,     0.97702,\n",
       "            0.97702,     0.97702,     0.97702,     0.97702,     0.97702,     0.97702,     0.97702,     0.97702,     0.97702,     0.97702,     0.97702,     0.97655,     0.97655,     0.97655,     0.97655,     0.97655,     0.97646,     0.97608,     0.97608,     0.97608,     0.97608,     0.97608,     0.97608,\n",
       "            0.97608,     0.97608,     0.97561,     0.97561,     0.97561,     0.97561,     0.97561,     0.97561,     0.97561,     0.97561,     0.97544,     0.97518,     0.97514,     0.97514,     0.97514,     0.97514,     0.97514,     0.97514,     0.97514,     0.97514,     0.97514,     0.97514,     0.97514,\n",
       "            0.97514,     0.97514,     0.97503,     0.97473,     0.97467,     0.97467,     0.97467,     0.97467,     0.97467,     0.97467,     0.97467,     0.97467,     0.97467,     0.97467,      0.9742,      0.9742,      0.9742,      0.9742,     0.97409,     0.97373,     0.97373,     0.97373,     0.97313,\n",
       "            0.97297,     0.97281,      0.9728,      0.9728,      0.9728,     0.97234,     0.97211,     0.97186,     0.97186,     0.97181,     0.97162,     0.97143,     0.97139,     0.97139,     0.97139,     0.97139,     0.97139,     0.97139,     0.97139,     0.97116,     0.97079,     0.97034,     0.96998,\n",
       "            0.96998,     0.96998,     0.96998,     0.96998,     0.96998,     0.96998,     0.96998,     0.96998,     0.96998,     0.96998,     0.96998,     0.96998,     0.96998,     0.96998,     0.96998,     0.96951,     0.96951,     0.96951,     0.96951,     0.96951,     0.96951,     0.96951,     0.96951,\n",
       "            0.96951,     0.96951,     0.96951,     0.96951,     0.96951,     0.96932,     0.96904,     0.96904,     0.96904,     0.96904,     0.96904,     0.96904,     0.96904,     0.96904,     0.96904,     0.96904,     0.96904,     0.96904,     0.96904,     0.96904,     0.96904,     0.96904,     0.96873,\n",
       "            0.96857,     0.96857,     0.96857,     0.96857,     0.96857,     0.96857,     0.96857,     0.96857,     0.96857,     0.96857,     0.96857,     0.96857,     0.96857,     0.96857,     0.96847,     0.96832,     0.96817,     0.96811,     0.96811,     0.96811,     0.96811,     0.96811,     0.96811,\n",
       "            0.96811,     0.96811,     0.96811,     0.96811,     0.96811,     0.96811,     0.96811,     0.96811,     0.96811,     0.96811,     0.96811,     0.96811,     0.96811,     0.96811,     0.96764,     0.96764,     0.96764,     0.96764,     0.96764,     0.96764,     0.96764,     0.96764,     0.96764,\n",
       "            0.96764,     0.96764,     0.96764,     0.96764,     0.96756,     0.96744,     0.96731,     0.96718,     0.96696,     0.96673,     0.96652,     0.96632,     0.96587,     0.96576,     0.96576,     0.96576,     0.96576,     0.96576,     0.96576,     0.96576,     0.96576,     0.96576,     0.96573,\n",
       "            0.96534,     0.96519,     0.96508,     0.96497,     0.96486,     0.96482,     0.96482,     0.96482,     0.96482,     0.96482,     0.96482,     0.96435,     0.96435,     0.96435,     0.96435,     0.96388,     0.96388,     0.96376,     0.96352,     0.96341,     0.96341,     0.96341,     0.96341,\n",
       "            0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,\n",
       "            0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96341,     0.96308,     0.96295,     0.96295,     0.96295,     0.96295,     0.96295,     0.96295,\n",
       "            0.96295,     0.96295,     0.96295,     0.96295,     0.96295,     0.96295,     0.96295,     0.96295,     0.96295,     0.96295,     0.96295,     0.96295,     0.96295,     0.96295,     0.96295,     0.96248,     0.96248,     0.96194,     0.96181,     0.96167,     0.96154,     0.96135,     0.96116,\n",
       "            0.96107,     0.96101,     0.96057,     0.96046,     0.96035,     0.96023,     0.96007,     0.95966,     0.95956,     0.95942,     0.95928,     0.95919,     0.95919,     0.95919,     0.95919,     0.95919,     0.95919,     0.95919,     0.95919,     0.95919,     0.95911,      0.9589,     0.95871,\n",
       "            0.95864,     0.95857,      0.9585,     0.95843,     0.95836,     0.95828,     0.95826,     0.95779,     0.95774,     0.95769,     0.95763,     0.95757,     0.95751,     0.95746,      0.9574,     0.95734,     0.95725,     0.95714,     0.95702,     0.95691,     0.95685,     0.95685,     0.95685,\n",
       "            0.95685,     0.95685,     0.95685,     0.95685,     0.95685,     0.95685,     0.95684,     0.95654,     0.95638,     0.95638,     0.95631,     0.95591,     0.95591,     0.95543,     0.95538,     0.95532,     0.95527,     0.95522,     0.95516,     0.95511,     0.95505,       0.955,     0.95495,\n",
       "            0.95491,     0.95487,     0.95483,      0.9548,     0.95476,     0.95472,     0.95468,     0.95464,      0.9546,     0.95456,     0.95452,     0.95444,     0.95431,     0.95418,     0.95406,      0.9539,     0.95373,     0.95357,     0.95324,      0.9531,     0.95263,     0.95246,     0.95224,\n",
       "            0.95209,     0.95198,     0.95187,     0.95177,     0.95169,     0.95169,     0.95169,     0.95169,     0.95169,     0.95169,     0.95169,     0.95169,     0.95163,     0.95142,     0.95122,     0.95102,     0.95074,     0.95045,     0.95028,     0.95028,      0.9501,     0.94981,     0.94981,\n",
       "            0.94981,     0.94981,     0.94981,     0.94968,     0.94923,     0.94908,     0.94893,     0.94887,     0.94859,     0.94841,     0.94841,     0.94841,     0.94841,     0.94841,     0.94841,     0.94841,     0.94841,     0.94841,     0.94841,     0.94841,     0.94841,     0.94841,     0.94827,\n",
       "            0.94809,      0.9479,     0.94771,     0.94753,     0.94747,     0.94746,      0.9471,      0.9469,     0.94677,     0.94664,     0.94653,      0.9464,     0.94621,     0.94606,     0.94606,     0.94606,     0.94606,     0.94606,     0.94606,     0.94606,     0.94558,      0.9454,     0.94522,\n",
       "            0.94504,     0.94485,     0.94467,     0.94418,     0.94418,     0.94418,     0.94418,       0.944,     0.94371,     0.94371,     0.94371,     0.94371,     0.94371,     0.94371,     0.94371,     0.94357,     0.94343,     0.94328,     0.94278,     0.94266,     0.94254,     0.94243,     0.94231,\n",
       "            0.94226,     0.94222,     0.94217,     0.94212,     0.94208,     0.94203,     0.94198,     0.94194,     0.94189,     0.94184,     0.94173,     0.94161,     0.94148,     0.94137,     0.94137,     0.94137,     0.94137,     0.94137,     0.94137,     0.94137,     0.94137,     0.94137,     0.94137,\n",
       "            0.94137,     0.94137,     0.94137,     0.94137,     0.94137,     0.94137,     0.94137,     0.94137,     0.94129,     0.94098,     0.94078,     0.94061,     0.94044,     0.94043,     0.94043,     0.94043,     0.94043,     0.94043,     0.94043,     0.94043,     0.94039,     0.94034,     0.94029,\n",
       "            0.94024,     0.94018,     0.94013,     0.94008,     0.94003,     0.93998,     0.93946,     0.93935,     0.93925,     0.93914,     0.93904,     0.93882,      0.9386,     0.93856,     0.93856,     0.93835,     0.93809,     0.93809,     0.93809,     0.93762,     0.93762,     0.93762,     0.93762,\n",
       "            0.93762,     0.93752,     0.93742,     0.93731,     0.93721,     0.93689,      0.9365,     0.93621,     0.93593,     0.93574,     0.93574,     0.93507,     0.93481,     0.93449,     0.93398,     0.93352,     0.93332,     0.93322,     0.93312,     0.93301,     0.93284,     0.93222,     0.93179,\n",
       "            0.93156,      0.9314,     0.93126,     0.93111,      0.9309,     0.93064,     0.92965,     0.92964,     0.92964,     0.92924,     0.92879,     0.92871,     0.92871,     0.92824,      0.9282,     0.92812,     0.92804,     0.92796,     0.92788,      0.9278,      0.9277,     0.92756,     0.92742,\n",
       "             0.9273,      0.9273,      0.9273,      0.9273,      0.9273,      0.9273,      0.9273,     0.92724,     0.92718,     0.92712,     0.92706,       0.927,     0.92693,     0.92687,     0.92636,     0.92636,     0.92636,     0.92636,     0.92636,     0.92618,     0.92585,     0.92578,     0.92571,\n",
       "            0.92564,     0.92556,     0.92549,     0.92542,     0.92532,     0.92523,     0.92513,     0.92504,     0.92494,     0.92481,     0.92467,     0.92454,     0.92427,     0.92394,     0.92368,     0.92321,     0.92308,     0.92308,     0.92273,     0.92246,     0.92227,     0.92204,     0.92169,\n",
       "            0.92094,     0.92016,     0.91977,     0.91965,     0.91952,      0.9194,     0.91915,     0.91886,     0.91886,      0.9185,     0.91739,     0.91699,     0.91628,     0.91557,     0.91557,      0.9151,      0.9151,      0.9151,     0.91484,     0.91443,     0.91417,     0.91417,      0.9141,\n",
       "            0.91395,     0.91379,     0.91359,     0.91331,     0.91276,     0.91268,     0.91176,     0.91155,     0.91123,     0.90984,     0.90958,     0.90882,     0.90835,     0.90782,     0.90639,     0.90597,     0.90558,     0.90534,     0.90449,     0.90247,      0.9015,      0.9013,      0.9011,\n",
       "            0.90031,     0.89941,     0.89871,     0.89795,     0.89681,     0.89574,     0.89549,     0.89493,     0.89394,     0.89356,     0.89284,     0.89219,      0.8915,     0.89104,     0.88987,     0.88867,      0.8883,     0.88822,     0.88814,     0.88805,     0.88797,     0.88768,     0.88683,\n",
       "            0.88658,     0.88574,     0.88455,     0.88421,     0.88393,     0.88361,     0.88303,      0.8827,     0.88237,     0.88111,      0.8794,     0.87859,     0.87774,     0.87697,     0.87655,     0.87448,     0.87321,     0.87253,     0.87198,     0.87151,     0.87021,     0.86937,      0.8686,\n",
       "            0.86714,     0.86677,     0.86645,     0.86561,     0.86512,     0.86413,     0.86203,     0.86136,     0.86022,     0.85931,      0.8584,     0.85662,     0.85579,     0.85523,     0.85435,     0.85283,     0.85178,     0.84825,     0.84731,     0.84548,     0.84324,     0.84019,     0.83856,\n",
       "             0.8341,     0.83181,     0.83024,     0.82926,     0.82653,      0.8227,     0.82219,     0.82061,     0.81797,     0.81661,     0.81429,     0.81061,     0.80833,     0.80637,     0.80456,     0.80365,     0.80184,     0.80073,     0.79687,      0.7939,      0.7915,     0.78775,     0.78667,\n",
       "            0.78473,     0.78145,     0.78006,     0.77824,     0.77571,     0.77418,     0.77208,     0.76843,     0.76601,     0.76364,     0.75894,     0.75595,      0.7552,     0.75126,     0.74671,     0.74421,     0.73965,     0.73736,     0.73421,     0.73184,      0.7255,     0.72023,     0.71538,\n",
       "            0.70985,     0.70459,     0.69947,     0.69018,     0.68419,     0.67791,     0.67068,     0.66233,        0.65,     0.63974,     0.63295,     0.62001,     0.60976,     0.59771,     0.58222,     0.57042,     0.55944,     0.54516,     0.53212,     0.51795,     0.50139,      0.4839,     0.47212,\n",
       "            0.46057,     0.44573,     0.43266,      0.4205,     0.40405,     0.38791,     0.37149,     0.36503,     0.34791,     0.33295,     0.31859,     0.31236,     0.30449,     0.29849,     0.29412,     0.28889,     0.28456,     0.27565,     0.27172,     0.26863,     0.26747,     0.26389,     0.25984,\n",
       "            0.25582,      0.2534,     0.25063,     0.24569,     0.24274,     0.24002,     0.23468,     0.22758,     0.21397,     0.20338,     0.19595,     0.18643,     0.17487,     0.16476,     0.15165,     0.13795,     0.12803,     0.11426,     0.10061,    0.087391,    0.079095,    0.069327,    0.061838,\n",
       "           0.054803,    0.044199,    0.039805,    0.036344,    0.033757,    0.030207,    0.026845,    0.026141,    0.024975,    0.024302,    0.023762,    0.023539,    0.023026,     0.02204,    0.021781,    0.021427,      0.0209,    0.020477,    0.020103,    0.019952,    0.019802,    0.019669,    0.019571,\n",
       "           0.019474,    0.019377,     0.01928,     0.01826,    0.017708,    0.016186,    0.015798,    0.014866,    0.013944,    0.013099,    0.012798,    0.012356,    0.012104,    0.011975,    0.011846,    0.011641,    0.010755,    0.010389,   0.0099181,   0.0090989,   0.0082783,   0.0077704,   0.0074187,\n",
       "          0.0072098,   0.0068844,   0.0063341,   0.0055975,   0.0054547,   0.0053118,   0.0051689,   0.0048314,   0.0044818,   0.0040005,    0.003496,   0.0031945,   0.0029756,   0.0024664,   0.0021373,   0.0019084,   0.0016113,    0.001269,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.7325564807294278\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.70464])\n",
       "names: {0: 'PLACA_AUTOMOVIL'}\n",
       "nt_per_class: array([2132])\n",
       "nt_per_image: array([2043])\n",
       "results_dict: {'metrics/precision(B)': 0.966984527243007, 'metrics/recall(B)': 0.9629455909943715, 'metrics/mAP50(B)': 0.9837651806203891, 'metrics/mAP50-95(B)': 0.7046444029637654, 'fitness': 0.7325564807294278}\n",
       "save_dir: PosixPath('ENTRENAMIENTO_YOLOV10S/YOLOV10S_AdamW_lr0.0005_wd0.0005_mos0')\n",
       "speed: {'preprocess': 0.4351436950255607, 'inference': 10.818117628050574, 'loss': 1.3133903635567451e-05, 'postprocess': 0.6541298680389079}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "path_yml = r'/Users/pepefv97/Downloads/DATOS_PLACAS/data.yaml'\n",
    "\n",
    "\n",
    "model = YOLO(\"yolov10s.pt\")      \n",
    "model.train(\n",
    "    data=path_yml, \n",
    "    epochs=10,\n",
    "    batch=32,\n",
    "    imgsz=512,\n",
    "    device=\"mps\",\n",
    "    freeze=10,\n",
    "    plots=True,\n",
    "    verbose=True,\n",
    "    amp=True,\n",
    "    optimizer=\"AdamW\",\n",
    "    lr0=0.0005,\n",
    "    weight_decay=0.0005,\n",
    "    mosaic=0,                \n",
    "    project=\"ENTRENAMIENTO_YOLOV10S\",\n",
    "    name=\"YOLOV10S_AdamW_lr0.0005_wd0.0005_mos0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f2e4ce-26b7-4ef6-94f4-24c3589c1d82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
